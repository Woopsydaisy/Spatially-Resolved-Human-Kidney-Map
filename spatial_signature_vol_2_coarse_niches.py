# -*- coding: utf-8 -*-
"""spatial signature Vol 2 coarse niches.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wF3VY0hM726TIfOuhjST8k0R_jE1-hA8
"""

!pip --quiet install scanpy
!pip --quiet install leidenalg
#!pip --quiet install squidpy

from google.colab import drive
drive.mount('/content/drive')

import csv
import anndata as ad
import gzip
import os
import scipy.io
import scanpy as sc
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from google.colab import drive
import leidenalg as la
from pathlib import Path
#import squidpy as sq

adata_all=sc.read_h5ad('/content/drive/MyDrive/Bernhard/Cosmx/SCVI/All_Runs/allCosmx_allGenes.h5ad')

adata = sc.read_h5ad('/content/drive/MyDrive/Bernhard/Cosmx/After_Cleaning/all_Cosmx_cleaned_neighbored.h5ad')

adata_all.obs['iTAL_subcluster_ME_20um']=adata.obs['iTAL_subcluster_ME_20um'].copy()
adata_all.obs['iPT_subcluster_ME_20um']=adata.obs['iPT_subcluster_ME_20um'].copy()
adata_all.obs['immune_subcluster_ME_20um']=adata.obs['immune_subcluster_ME_20um'].copy()
adata_all.obs['Fibroblast_subcluster_ME_20um']=adata.obs['Fibroblast_subcluster_ME_20um'].copy()

adata

adata_all.obs['cluster_labels_annotated_coarse_coarse']=adata.obs['cluster_labels_annotated_coarse_coarse'].copy()

adata_all=adata_all[adata_all.obs['cluster_labels_annotated_coarse_coarse']!='outlier']
adata_all

adata_all.X = adata_all.layers["counts"]
sc.pp.log1p(adata_all)
sc.tl.rank_genes_groups(adata_all, groupby='cluster_labels_annotated_coarse_coarse',method='wilcoxon', pts = True)
sc.pl.rank_genes_groups(adata_all, n_genes=25, sharey=False)

unique_groups = adata_all.obs['cluster_labels_annotated_coarse_coarse'].unique()
for group1 in unique_groups:
    if group1=='outlier':
      continue
    for group2 in unique_groups:
        if group1 != group2:
            print(f"Comparing group: {group1} vs {group2}")

import scanpy as sc
import numpy as np
import pandas as pd
import gc
# Assuming adata_all is your AnnData object
adata_all.X = adata_all.layers["counts"]
sc.pp.log1p(adata_all)

# Get all unique groups from different columns
unique_groups1 = adata_all.obs['cluster_labels_annotated_coarse_coarse'].unique()

# Function to perform pairwise comparisons and save results
def perform_pairwise_comparisons(unique_groups, group_column_name):
    for group1 in unique_groups:
        group_results = []
        gc.collect()
        for group2 in unique_groups:
            if group1 != group2:
                print(f"Comparing group: {group1} vs {group2}")

                # Define a new column for the comparison
                adata_all.obs['comparison'] = adata_all.obs[group_column_name].apply(
                    lambda x: group1 if x == group1 else (group2 if x == group2 else None)
                )

                # Filter the data to include only the relevant groups
                adata_pairwise = adata_all[adata_all.obs['comparison'].notna()]

                # Perform rank genes groups analysis
                sc.tl.rank_genes_groups(adata_pairwise, groupby='comparison', method='wilcoxon', pts=True)

                # Retrieve and process the results
                de_results = adata_pairwise.uns['rank_genes_groups']
                gene_names = de_results['names'][group1]
                gene_scores = de_results['scores'][group1]
                gene_logfoldchanges = de_results['logfoldchanges'][group1]
                gene_pvals = de_results['pvals'][group1]
                gene_pvals_adj = de_results['pvals_adj'][group1]

                # Get the total number of cells compared
                num_cells_compared = adata_pairwise.shape[0]

                # Create a DataFrame
                df = pd.DataFrame({
                    'Gene': gene_names,
                    f'{group1}_vs_{group2}_Score': gene_scores,
                    f'{group1}_vs_{group2}_LogFoldChange': gene_logfoldchanges,
                    f'{group1}_vs_{group2}_pValue': gene_pvals,
                    f'{group1}_vs_{group2}_pValue_adj': gene_pvals_adj,
                    f'{group1}_vs_{group2}_NumCellsCompared': num_cells_compared
                })

                # Merge with the existing results
                if group_results:
                    group_results.append(df.set_index('Gene'))
                else:
                    group_results.append(df.set_index('Gene'))
                gc.collect()
        # Concatenate results for the current group1
        if group_results:
            comparison_results = pd.concat(group_results, axis=1).reset_index()
            output_file = f'/content/drive/MyDrive/Bernhard/Cosmx/After_Cleaning/spatial_signatures/niches/{group_column_name}_{group1}_pairwise_comparisons_DEGs.csv'
            comparison_results.to_csv(output_file, index=False)
            print(f"Saved results for {group1} to {output_file}")

    # Clean up
    del adata_all.obs['comparison']
    gc.collect()

# Perform pairwise comparisons for each group set
perform_pairwise_comparisons(unique_groups1, 'cluster_labels_annotated_coarse_coarse')

import os
import pandas as pd

folder_name = '/content/drive/MyDrive/Bernhard/Cosmx/After_Cleaning/spatial_signatures/niches'

# Create a dictionary to store dataframes
dataframes = {}

# List all files in the folder
for filename in os.listdir(folder_name):
    if filename.endswith('.csv'):
        # Create the dataframe name by stripping off the '.csv' extension and replacing spaces with underscores
        df_name = filename[:-4].replace(' ', '_')
        df_name=df_name.replace('+','_')
        df_name=df_name.replace('_pairwise_comparisons_DEGs', '')
        # Read the CSV file into a dataframe
        df_path = os.path.join(folder_name, filename)
        dataframes[df_name] = pd.read_csv(df_path)
        print(f"Loaded dataframe: {df_name} with shape: {dataframes[df_name].shape}")

for df_name, df in dataframes.items():
    globals()[df_name] = df
    print(f"Created dataframe variable: {df_name} with shape: {df.shape}")

##remove the outlier column for the metaanalysis of the non outlier MEs
for df_name, df in dataframes.items():
    if 'outlier' not in df_name:
        # Remove columns that contain 'outlier' in their name
        columns_to_remove = [col for col in df.columns if 'outlier' in col]
        df.drop(columns=columns_to_remove, inplace=True)
        print(f"Processed dataframe: {df_name} with shape: {df.shape}")

import os
import pandas as pd
import numpy as np
from scipy.stats import norm

# Function to apply Stouffer's test with weights on scores
def stouffer_test_with_weights(scores, weights):
    weighted_z = np.sum(scores * weights) / np.sqrt(np.sum(weights**2))
    combined_p = norm.sf(weighted_z)
    return combined_p

# Folder containing the dataframes
folder_name = '/content/drive/MyDrive/Bernhard/Cosmx/After_Cleaning/spatial_signatures/niches'

# Process dataframes that do not contain 'outlier' in their title
for df_name, df in dataframes.items():
    if 'outlier' not in df_name:
        # Extract score columns and corresponding weights (number of cells compared)
        score_columns = [col for col in df.columns if col.endswith('_Score')]
        weight_columns = [col for col in df.columns if col.endswith('_NumCellsCompared')]

        # Apply Stouffer's test for each gene
        combined_pvals = df.apply(lambda row: stouffer_test_with_weights(row[score_columns].values, row[weight_columns].values), axis=1)

        # Create a new DataFrame with combined p-values
        meta_analysis_df = df[['Gene']].copy()
        meta_analysis_df['Combined_pValue'] = combined_pvals
        meta_analysis_df = meta_analysis_df.sort_values(by='Combined_pValue', ascending=True).reset_index(drop=True)
        # Save the results to a new CSV file
        output_path = os.path.join(folder_name, f"{df_name}_meta_analysis.csv")
        meta_analysis_df.to_csv(output_path, index=False)
        print(f"Saved meta-analysis results for {df_name} to {output_path}")
        print(meta_analysis_df)

# Print a message indicating the processing is complete
print("Completed processing and meta-analysis for all dataframes.")

import os
import pandas as pd

folder_name = '/content/drive/MyDrive/Bernhard/Cosmx/After_Cleaning/spatial_signatures/niches'

# List all files in the folder and load only those containing 'meta_analysis' in their filename
for filename in os.listdir(folder_name):
    if filename.endswith('.csv') and 'meta_analysis' in filename:
        # Create the dataframe name by stripping off the '.csv' extension and replacing spaces with underscores
        df_name = filename[:-4].replace(' ', '_')
        df_name = df_name.replace('+', '_')
        # Read the CSV file into a dataframe
        df_path = os.path.join(folder_name, filename)
        globals()[df_name] = pd.read_csv(df_path)
        print(f"Loaded dataframe: {df_name} with shape: {globals()[df_name].shape}")

# Optionally, print the names and shapes of all created dataframes
for var_name in list(globals().keys()):
    if isinstance(globals()[var_name], pd.DataFrame):
        print(f"Created dataframe variable: {var_name} with shape: {globals()[var_name].shape}")

import os
import pandas as pd

folder_name = '/content/drive/MyDrive/Bernhard/Cosmx/After_Cleaning/spatial_signatures/niches'

# Function to extract the new column name from the dataframe name
def extract_column_name(df_name):
    words = df_name.split('_')
    return '_'.join(words[:-1])

# Function to add index as a column
def add_index_column(df, df_name):
    new_column_name = extract_column_name(df_name)
    df[new_column_name] = df.index
    return df

# List all files in the folder and load only those containing 'immune' and 'meta_analysis' in their filename
immune_meta_analysis_dfs = []

for filename in os.listdir(folder_name):
    if filename.endswith('.csv') and 'cluster_labels_annotated_coarse_coarse' in filename and 'meta_analysis' in filename:
        # Create the dataframe name by stripping off the '.csv' extension and replacing spaces with underscores
        df_name = filename[:-4].replace(' ', '_')
        df_name = df_name.replace('+', '_')
        # Read the CSV file into a dataframe
        df_path = os.path.join(folder_name, filename)
        df = pd.read_csv(df_path)
        # Add index as a column
        df = add_index_column(df, df_name)
        immune_meta_analysis_dfs.append(df)
        print(f"Loaded dataframe: {df_name} with shape: {df.shape}")

# Merge all dataframes on the 'Gene' column
if immune_meta_analysis_dfs:
    merged_df = immune_meta_analysis_dfs[0]
    merged_df=merged_df.drop('Combined_pValue', axis=1)
    for df in immune_meta_analysis_dfs[1:]:
        df=df.drop('Combined_pValue', axis=1)
        merged_df = pd.merge(merged_df, df, on='Gene', how='outer', suffixes=(False, False))

    # Save the merged dataframe to a new CSV file
    output_path = '/content/drive/MyDrive/Bernhard/Cosmx/After_Cleaning/spatial_signatures/niches/niches_meta_analysis.csv'
    merged_df.columns = [col.replace('cluster_labels_annotated_coarse_coarse', '') for col in merged_df.columns]
    merged_df.columns = [col.replace('_meta', '') for col in merged_df.columns]
    merged_df['Min_Value_Column'] = merged_df.loc[:, merged_df.columns != 'Gene'].idxmin(axis=1)
    merged_df.to_csv(output_path, index=False)
    print(f"Saved merged dataframe to {output_path}")
    print(merged_df)
else:
    print("No matching dataframes found.")

"""now we take DEGs between all groups and simply eliminate genes from the DEGs for each microenvironment using our metaanalysis"""

adata_all.X = adata_all.layers["counts"]
sc.pp.log1p(adata_all)
sc.tl.rank_genes_groups(adata_all, groupby='cluster_labels_annotated_coarse_coarse',method='wilcoxon', pts = True)
sc.pl.rank_genes_groups(adata_all, n_genes=25, sharey=False)

de_results = adata_all.uns['rank_genes_groups']
for group in de_results['names'].dtype.names:
        print(group)
        gene_names = de_results['names'][group]
        gene_scores = de_results['scores'][group]
        gene_logfoldchanges = de_results['logfoldchanges'][group]
        gene_pvals = de_results['pvals'][group]
        gene_pvals_adj = de_results['pvals_adj'][group]

        # Create a DataFrame
        df = pd.DataFrame({
            'Gene': gene_names,
            'Score': gene_scores,
            'LogFoldChange': gene_logfoldchanges,
            'pValue': gene_pvals,
            'pValue_adj': gene_pvals_adj
        })
        very_small_value = 1e-310
        df['pValue_adj'] = df['pValue_adj'].replace(0, very_small_value)
        df["pi_score"] = -1 * np.log10(df["pValue_adj"]) * df["LogFoldChange"]
        print(df.head(55))
        df.to_csv(f'/content/drive/MyDrive/Bernhard/Cosmx/After_Cleaning/spatial_signatures/niches/DEGs_for_signature/niches_{group}_DEGs.csv')

metaanalysis_niche=pd.read_csv('/content/drive/MyDrive/Bernhard/Cosmx/After_Cleaning/spatial_signatures/niches/niches_meta_analysis.csv')

import os
import pandas as pd

folder_name = '/content/drive/MyDrive/Bernhard/Cosmx/After_Cleaning/spatial_signatures/niches/DEGs_for_signature'

# List all files in the folder and load only those not containing 'outlier' in their filename
for filename in os.listdir(folder_name):
    if 'outlier' in filename:
        continue
    # Create the dataframe name by stripping off the '.csv' extension and replacing spaces with underscores
    df_name = filename[:-4].replace(' ', '_')
    df_name = df_name.replace('+', '_')
    # Read the CSV file into a dataframe
    df_path = os.path.join(folder_name, filename)
    globals()[df_name] = pd.read_csv(df_path)
    print(f"Loaded dataframe: {df_name} with shape: {globals()[df_name].shape}")

metaanalysis_niche['Min_Value_Column'].unique()

import os
import pandas as pd

# Assuming the dataframes are already loaded and processed as per your previous steps

# Initialize the top_genes dictionary
top_genes = {}

# Function to get top 20 genes
def get_top_genes(df, df_name):
    df = df[~df['Gene'].isin(['MHC I', 'MALAT1', 'CCL3/L1/L3','XCL1/2', 'XIST', 'SRY','HLA-DQB1/2','C11orf96', 'HSPA1A/B'])]
    top_genes[df_name] = df.head(10)['Gene'].tolist()

# Load and process the dataframes
folder_name = '/content/drive/MyDrive/Bernhard/Cosmx/After_Cleaning/spatial_signatures/niches/DEGs_for_signature'

for filename in os.listdir(folder_name):
    if 'outlier' in filename:
        continue
    df_name = filename[:-4].replace(' ', '_').replace('+', '_')
    df_path = os.path.join(folder_name, filename)
    df = pd.read_csv(df_path)
    if 'Unnamed: 0' in df.columns:
        df = df.drop('Unnamed: 0', axis=1)
    df = df[df['pValue_adj'] < 0.01]

    # Merge with the metaanalysis_immune dataframe based on the specific conditions
    if 'niches_TAL_Niche_DEGs' in df_name:
        filtered_metaanalysis = metaanalysis_niche[metaanalysis_niche['Min_Value_Column'] == '_TAL_Niche']
        merged_df = pd.merge(df, filtered_metaanalysis, on='Gene', how='inner')
        merged_df = merged_df[merged_df['LogFoldChange'] > 0].sort_values(by='pi_score', ascending=False)
        get_top_genes(merged_df, df_name)
    elif 'niches_CNT_Niche_DEGs' in df_name:
        filtered_metaanalysis = metaanalysis_niche[metaanalysis_niche['Min_Value_Column'] == '_CNT_Niche']
        merged_df = pd.merge(df, filtered_metaanalysis, on='Gene', how='inner')
        merged_df = merged_df[merged_df['LogFoldChange'] > 0].sort_values(by='pi_score', ascending=False)
        get_top_genes(merged_df, df_name)
    elif 'niches_iTAL_Niche_DEGs' in df_name:
        filtered_metaanalysis = metaanalysis_niche[metaanalysis_niche['Min_Value_Column'] == '_iTAL_Niche']
        merged_df = pd.merge(df, filtered_metaanalysis, on='Gene', how='inner')
        merged_df = merged_df[merged_df['LogFoldChange'] > 0].sort_values(by='pi_score', ascending=False)
        get_top_genes(merged_df, df_name)
    elif 'niches_PT_Niche_DEGs' in df_name:
        filtered_metaanalysis = metaanalysis_niche[metaanalysis_niche['Min_Value_Column'] == '_PT_Niche']
        merged_df = pd.merge(df, filtered_metaanalysis, on='Gene', how='inner')
        merged_df = merged_df[merged_df['LogFoldChange'] > 0].sort_values(by='pi_score', ascending=False)
        get_top_genes(merged_df, df_name)
    elif 'niches_CD_Niche_DEGs' in df_name:
        filtered_metaanalysis = metaanalysis_niche[metaanalysis_niche['Min_Value_Column'] == '_CD_Niche']
        merged_df = pd.merge(df, filtered_metaanalysis, on='Gene', how='inner')
        merged_df = merged_df[merged_df['LogFoldChange'] > 0].sort_values(by='pi_score', ascending=False)
        get_top_genes(merged_df, df_name)
    elif 'niches_iPT_Niche_DEGs' in df_name:
        filtered_metaanalysis = metaanalysis_niche[metaanalysis_niche['Min_Value_Column'] == '_iPT_Niche']
        merged_df = pd.merge(df, filtered_metaanalysis, on='Gene', how='inner')
        merged_df = merged_df[merged_df['LogFoldChange'] > 0].sort_values(by='pi_score', ascending=False)
        get_top_genes(merged_df, df_name)
    elif 'niches_Vascular_Niche_DEGs' in df_name:
        filtered_metaanalysis = metaanalysis_niche[metaanalysis_niche['Min_Value_Column'] == '_Vascular_Niche']
        merged_df = pd.merge(df, filtered_metaanalysis, on='Gene', how='inner')
        merged_df = merged_df[merged_df['LogFoldChange'] > 0].sort_values(by='pi_score', ascending=False)
        get_top_genes(merged_df, df_name)
    elif 'niches_Immune_Niche_DEGs' in df_name:
        filtered_metaanalysis = metaanalysis_niche[metaanalysis_niche['Min_Value_Column'] == '_Immune_Niche']
        merged_df = pd.merge(df, filtered_metaanalysis, on='Gene', how='inner')
        merged_df = merged_df[merged_df['LogFoldChange'] > 0].sort_values(by='pi_score', ascending=False)
        get_top_genes(merged_df, df_name)
    elif 'niches_Fibroblast_Niche_DEGs' in df_name:
        filtered_metaanalysis = metaanalysis_niche[metaanalysis_niche['Min_Value_Column'] == '_Fibroblast_Niche']
        merged_df = pd.merge(df, filtered_metaanalysis, on='Gene', how='inner')
        merged_df = merged_df[merged_df['LogFoldChange'] > 0].sort_values(by='pi_score', ascending=False)
        get_top_genes(merged_df, df_name)
    elif 'niches_Glomerular_Niche_DEGs' in df_name:
        filtered_metaanalysis = metaanalysis_niche[metaanalysis_niche['Min_Value_Column'] == '_Glomerular_Niche']
        merged_df = pd.merge(df, filtered_metaanalysis, on='Gene', how='inner')
        merged_df = merged_df[merged_df['LogFoldChange'] > 0].sort_values(by='pi_score', ascending=False)
        get_top_genes(merged_df, df_name)

# Print the top_genes dictionary
for key, value in top_genes.items():
    print(f"{key}: {value}")

expression_matrix = pd.read_csv('/content/Tridentalltpm.csv', sep= ';')

expression_matrix=expression_matrix.set_index('GeneSymbol')

expression_matrix=expression_matrix.T

expression_matrix = expression_matrix[expression_matrix.index.str.endswith('G')] ###G for the Glomclustering

expression_matrix.index = expression_matrix.index.str.rstrip('G')

expression_matrix

import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans

# Assuming expression_matrix is your DataFrame containing bulk sequencing data

# Initialize an empty DataFrame to store the cluster labels
cluster_labels_df = pd.DataFrame(index=expression_matrix.index)

# Function to process and plot PCA for a given gene set
def process_and_plot_pca(genes_to_score, expression_matrix, plot_title, output_file):
    # Filter genes that are in the expression_matrix
    valid_genes = [gene for gene in genes_to_score if gene in expression_matrix.columns]
    if not valid_genes:
        print(f"No valid genes found for {plot_title}")
        return

    # Select the genes for PCA
    data = expression_matrix[valid_genes]

    # Center the data by subtracting the mean
    data_centered = data - data.mean()

    # Scale the data to the range (-1, 1)
    scaler = MinMaxScaler(feature_range=(-1, 1))
    data_scaled = scaler.fit_transform(data_centered)

    # Convert scaled data back to DataFrame for consistency
    data_scaled_df = pd.DataFrame(data_scaled, index=data.index, columns=data.columns)

    # Perform PCA
    pca = PCA(n_components=2)  # Reduce to 2 components for 2D visualization
    principal_components = pca.fit_transform(data_scaled_df)

    # Create a DataFrame with the principal components
    pca_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'], index=data.index)

    # Perform KMeans clustering
    k = 2  # Adjust based on your specific needs
    kmeans = KMeans(n_clusters=k, random_state=0)
    kmeans.fit(data_scaled_df)
    labels = kmeans.labels_

    # Add cluster labels to the PCA DataFrame
    pca_df['Cluster'] = labels

    # Add the cluster labels to the cluster_labels_df
    cluster_labels_df[plot_title] = labels
    cluster_labels_df[f'{plot_title}_score']=data_scaled_df.sum(axis=1)
    # Plot the PCA
    plt.figure(figsize=(6, 4))
    ax = sns.scatterplot(x='PC1', y='PC2', hue='Cluster', data=pca_df, palette='tab10', s=50, alpha=0.8)
    plt.title(plot_title)
    plt.xlabel('Principal Component 1')
    plt.ylabel('Principal Component 2')
    plt.legend(title='Cluster', frameon=False)
    plt.grid(False)
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    plt.tight_layout()
    # Save the plot
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    plt.show()

    # Optional: Print explained variance to understand the importance of each component
    print(f"Explained variance ratio for {plot_title}:", pca.explained_variance_ratio_)

# Iterate through each key in the top_genes dictionary
for gene_set_name, genes_to_score in top_genes.items():
    plot_title = f'PCA of Gene Expression Data: {gene_set_name}'
    output_file = f'PCA_plot_{gene_set_name}.png'
    process_and_plot_pca(genes_to_score, expression_matrix, plot_title, output_file)

# Display the cluster labels DataFrame
print(cluster_labels_df)

# Strip 'PCA of Gene Expression Data: ' and '_DEGs' from column names
new_columns = [col.replace('PCA of Gene Expression Data: ', '').replace('_DEGs', '') for col in cluster_labels_df.columns]
cluster_labels_df.columns = new_columns

# Display the updated cluster labels DataFrame
print(cluster_labels_df)

for col in cluster_labels_df.columns:
    # Check if the column name ends with '_score'
    if col.endswith('_score'):
        # Calculate the mean of the score column
        mean_score = cluster_labels_df[col].mean()

        # Find the corresponding label column by removing '_score'
        label_col = col.replace('_score', '')

        # Replace 1 and 0 with 'high' and 'low' based on the mean score
        cluster_labels_df[label_col] = cluster_labels_df.apply(
            lambda row: 'high' if row[col] > mean_score else 'low', axis=1
        )

# Display the updated DataFrame
#print(cluster_labels_df)

cluster_labels_df.to_csv('10_spatialgenes_clustering_trident_niches_glom.csv', index=True)

!pip install --quiet plotly

cluster_labels_df.columns

import pandas as pd
import plotly.graph_objects as go

# Assuming cluster_labels_df is your DataFrame
#10 genes
# Define the columns of interest in sequential order
columns_of_interest = ['niches_CD_Niche', 'niches_CNT_Niche', 'niches_Fibroblast_Niche', 'niches_Glomerular_Niche', 'niches_Immune_Niche',
                       'niches_PT_Niche','niches_TAL_Niche', 'niches_Vascular_Niche','niches_iPT_Niche','niches_iTAL_Niche']

# Prepare data for the Sankey diagram
flows = []
labels = []
for i in range(len(columns_of_interest) - 1):
    src_col = columns_of_interest[i]
    tgt_col = columns_of_interest[i + 1]

    flow_counts = cluster_labels_df.groupby([src_col, tgt_col]).size().reset_index(name='count')

    for _, row in flow_counts.iterrows():
        src_label = f"{src_col}_{row[src_col]}"
        tgt_label = f"{tgt_col}_{row[tgt_col]}"

        if src_label not in labels:
            labels.append(src_label)
        if tgt_label not in labels:
            labels.append(tgt_label)

        flows.append({
            'source': labels.index(src_label),
            'target': labels.index(tgt_label),
            'value': row['count']
        })

# Create the Sankey plot
fig = go.Figure(go.Sankey(
    node=dict(
        pad=15,
        thickness=20,
        line=dict(color="black", width=0.5),
        label=labels
    ),
    link=dict(
        source=[flow['source'] for flow in flows],
        target=[flow['target'] for flow in flows],
        value=[flow['value'] for flow in flows]
    )
))

fig.update_layout(title_text="Flow from Subclusters to Status", font_size=10)
fig.show()

import pandas as pd
import plotly.graph_objects as go

# Assuming cluster_labels_df is your DataFrame
#5 genes
# Define the columns of interest in sequential order
columns_of_interest = ['niches_CD_Niche', 'niches_CNT_Niche', 'niches_Fibroblast_Niche', 'niches_Glomerular_Niche', 'niches_Immune_Niche',
                       'niches_PT_Niche','niches_TAL_Niche', 'niches_Vascular_Niche','niches_iPT_Niche','niches_iTAL_Niche']

# Prepare data for the Sankey diagram
flows = []
labels = []
for i in range(len(columns_of_interest) - 1):
    src_col = columns_of_interest[i]
    tgt_col = columns_of_interest[i + 1]

    flow_counts = cluster_labels_df.groupby([src_col, tgt_col]).size().reset_index(name='count')

    for _, row in flow_counts.iterrows():
        src_label = f"{src_col}_{row[src_col]}"
        tgt_label = f"{tgt_col}_{row[tgt_col]}"

        if src_label not in labels:
            labels.append(src_label)
        if tgt_label not in labels:
            labels.append(tgt_label)

        flows.append({
            'source': labels.index(src_label),
            'target': labels.index(tgt_label),
            'value': row['count']
        })

# Create the Sankey plot
fig = go.Figure(go.Sankey(
    node=dict(
        pad=15,
        thickness=20,
        line=dict(color="black", width=0.5),
        label=labels
    ),
    link=dict(
        source=[flow['source'] for flow in flows],
        target=[flow['target'] for flow in flows],
        value=[flow['value'] for flow in flows]
    )
))

fig.update_layout(title_text="Flow from Subclusters to Status", font_size=10)
fig.show()

import pandas as pd
import plotly.graph_objects as go

# Assuming cluster_labels_df is your DataFrame
#15 genes
# Define the columns of interest in sequential order
columns_of_interest = ['niches_CD_Niche', 'niches_CNT_Niche', 'niches_Fibroblast_Niche', 'niches_Glomerular_Niche', 'niches_Immune_Niche',
                       'niches_PT_Niche','niches_TAL_Niche', 'niches_Vascular_Niche','niches_iPT_Niche','niches_iTAL_Niche']

# Prepare data for the Sankey diagram
flows = []
labels = []
for i in range(len(columns_of_interest) - 1):
    src_col = columns_of_interest[i]
    tgt_col = columns_of_interest[i + 1]

    flow_counts = cluster_labels_df.groupby([src_col, tgt_col]).size().reset_index(name='count')

    for _, row in flow_counts.iterrows():
        src_label = f"{src_col}_{row[src_col]}"
        tgt_label = f"{tgt_col}_{row[tgt_col]}"

        if src_label not in labels:
            labels.append(src_label)
        if tgt_label not in labels:
            labels.append(tgt_label)

        flows.append({
            'source': labels.index(src_label),
            'target': labels.index(tgt_label),
            'value': row['count']
        })

# Create the Sankey plot
fig = go.Figure(go.Sankey(
    node=dict(
        pad=15,
        thickness=20,
        line=dict(color="black", width=0.5),
        label=labels
    ),
    link=dict(
        source=[flow['source'] for flow in flows],
        target=[flow['target'] for flow in flows],
        value=[flow['value'] for flow in flows]
    )
))

fig.update_layout(title_text="Flow from Subclusters to Status", font_size=10)
fig.show()

import pandas as pd
import plotly.graph_objects as go

# Assuming cluster_labels_df is your DataFrame
#15 genes
# Define the columns of interest in sequential order
columns_of_interest = ['niches_CD_Niche', 'niches_CNT_Niche', 'niches_Fibroblast_Niche', 'niches_Glomerular_Niche', 'niches_Immune_Niche',
                       'niches_PT_Niche','niches_TAL_Niche', 'niches_Vascular_Niche','niches_iPT_Niche','niches_iTAL_Niche']

# Prepare data for the Sankey diagram
flows = []
labels = []
for i in range(len(columns_of_interest) - 1):
    src_col = columns_of_interest[i]
    tgt_col = columns_of_interest[i + 1]

    flow_counts = cluster_labels_df.groupby([src_col, tgt_col]).size().reset_index(name='count')

    for _, row in flow_counts.iterrows():
        src_label = f"{src_col}_{row[src_col]}"
        tgt_label = f"{tgt_col}_{row[tgt_col]}"

        if src_label not in labels:
            labels.append(src_label)
        if tgt_label not in labels:
            labels.append(tgt_label)

        flows.append({
            'source': labels.index(src_label),
            'target': labels.index(tgt_label),
            'value': row['count']
        })

# Create the Sankey plot
fig = go.Figure(go.Sankey(
    node=dict(
        pad=15,
        thickness=20,
        line=dict(color="black", width=0.5),
        label=labels
    ),
    link=dict(
        source=[flow['source'] for flow in flows],
        target=[flow['target'] for flow in flows],
        value=[flow['value'] for flow in flows]
    )
))

fig.update_layout(title_text="Flow from Subclusters to Status", font_size=10)
fig.show()

import pandas as pd
import plotly.graph_objects as go

# Assuming cluster_labels_df is your DataFrame
#5 genes
# Define the columns of interest in sequential order
columns_of_interest = ['niches_CD_Niche', 'niches_CNT_Niche', 'niches_Fibroblast_Niche', 'niches_Glomerular_Niche', 'niches_Immune_Niche',
                       'niches_PT_Niche','niches_TAL_Niche', 'niches_Vascular_Niche','niches_iPT_Niche','niches_iTAL_Niche']

# Prepare data for the Sankey diagram
flows = []
labels = []
for i in range(len(columns_of_interest) - 1):
    src_col = columns_of_interest[i]
    tgt_col = columns_of_interest[i + 1]

    flow_counts = cluster_labels_df.groupby([src_col, tgt_col]).size().reset_index(name='count')

    for _, row in flow_counts.iterrows():
        src_label = f"{src_col}_{row[src_col]}"
        tgt_label = f"{tgt_col}_{row[tgt_col]}"

        if src_label not in labels:
            labels.append(src_label)
        if tgt_label not in labels:
            labels.append(tgt_label)

        flows.append({
            'source': labels.index(src_label),
            'target': labels.index(tgt_label),
            'value': row['count']
        })

# Create the Sankey plot
fig = go.Figure(go.Sankey(
    node=dict(
        pad=15,
        thickness=20,
        line=dict(color="black", width=0.5),
        label=labels
    ),
    link=dict(
        source=[flow['source'] for flow in flows],
        target=[flow['target'] for flow in flows],
        value=[flow['value'] for flow in flows]
    )
))

fig.update_layout(title_text="Flow from Subclusters to Status", font_size=10)
fig.show()

# Select columns that have '_score' at the end
columns_to_keep = [col for col in cluster_labels_df.columns if col.endswith('_score')]

# Keep only the selected columns
cluster_labels_df = cluster_labels_df[columns_to_keep]

# Display the resulting dataframe to verify
print(cluster_labels_df.shape)

# Replace 'Fibroblast_Fibroblast' with 'Fibro' in the column names
cluster_labels_df.columns = cluster_labels_df.columns.str.replace('_score', '')
cluster_labels_df.columns = cluster_labels_df.columns.str.replace('niches_', '')
# Display the updated dataframe to verify the changes
#print(cluster_labels_df)

# Compute the Pearson correlation matrix
correlation_matrix = cluster_labels_df.corr(method='pearson')

# Display the correlation matrix
#print(correlation_matrix)

# 10 genes
plt.figure(figsize=(10, 8))
ax = sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', vmin=0)
ax.xaxis.tick_top()  # Move x-axis labels to the top
plt.xticks(rotation=90)  # Rotate the x-axis labels for better readability
plt.title('')
plt.show()

"""now with Tubule RNA"""

expression_matrix = pd.read_csv('/content/drive/MyDrive/Bernhard/BulkSeq/HK.Biobank.Tubule.TPM_n900_230928.csv', sep= ';')

expression_matrix=expression_matrix.drop('Unnamed: 0', axis=1)

expression_matrix=expression_matrix.set_index('Symbol')

expression_matrix.index.name=None

expression_matrix=expression_matrix.T

expression_matrix.index = expression_matrix.index.str.rstrip('T')

expression_matrix = np.log2(expression_matrix + 1)

expression_matrix

biobank=pd.read_csv('/content/Susztak_Lab_Biobank_122023_subset_scored.csv')

biobank=biobank.set_index('ID')

biobank=biobank.drop(['pos', 'Disease', 'GFR', 'DM', 'HTN', 'Age', 'Gender', 'Race',
       'Collection_Site', 'Height_cm', 'Weight_kg', 'BMI',
       'pct_glom_sclerosis', 'Tubules_Atrophy ',
       'Glomeruli_Total_num', 'Glomeruli_Globally Schlerotic_num',
       'Glomeruli_globally_Schlerotic_pct',
       'Glomeruli_Segmentally_Schlerotic_num', 'Glomeruli_Wall_Thickening_0_3',
       'Glomeruli_Hypoperfused_0_3', 'Glomeruli_Mesangial_Matrix_0_3',
       'Glomeruli_Mesangial_Cellularity_0_3', 'Glomeruli_KW_Nodules_0_1',
       'Glomeruli_Pericapsular_Fibrosis_0_2', 'Tubules_pct_Atrophy ',
       'Tubules_pct_Acute_Tubular_Injury', 'Tubules_Reabsorption_0_3',
       'Interstitium_Lymphocytic_Infiltrate_0_3',
       'Interstitium_Plasmacytic_Infiltrate_0_3',
       'Interstitium_Eosinophils_0_3', 'Vessels_Medial_Thickening_0_3',
       'Vessels_Intimal_Fibrosis_0_3', 'Vessels_Arteriolar_Hyalinosis_0_3'], axis=1)

biobank=biobank.astype(float)

import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans

# Assuming expression_matrix is your DataFrame containing bulk sequencing data

# Initialize an empty DataFrame to store the cluster labels
cluster_labels_df = pd.DataFrame(index=expression_matrix.index)

# Function to process and plot PCA for a given gene set
def process_and_plot_pca(genes_to_score, expression_matrix, plot_title, output_file):
    # Filter genes that are in the expression_matrix
    valid_genes = [gene for gene in genes_to_score if gene in expression_matrix.columns]
    if not valid_genes:
        print(f"No valid genes found for {plot_title}")
        return

    # Select the genes for PCA
    data = expression_matrix[valid_genes]

    # Center the data by subtracting the mean
    data_centered = data - data.mean()

    # Scale the data to the range (-1, 1)
    scaler = MinMaxScaler(feature_range=(-1, 1))
    data_scaled = scaler.fit_transform(data_centered)

    # Convert scaled data back to DataFrame for consistency
    data_scaled_df = pd.DataFrame(data_scaled, index=data.index, columns=data.columns)

    # Perform PCA
    pca = PCA(n_components=2)  # Reduce to 2 components for 2D visualization
    principal_components = pca.fit_transform(data_scaled_df)

    # Create a DataFrame with the principal components
    pca_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'], index=data.index)

    # Perform KMeans clustering
    k = 2  # Adjust based on your specific needs
    kmeans = KMeans(n_clusters=k, random_state=0)
    kmeans.fit(data_scaled_df)
    labels = kmeans.labels_

    # Add cluster labels to the PCA DataFrame
    pca_df['Cluster'] = labels

    # Add the cluster labels to the cluster_labels_df
    cluster_labels_df[plot_title] = labels
    cluster_labels_df[f'{plot_title}_score']=data_scaled_df.sum(axis=1)
    # Plot the PCA
    plt.figure(figsize=(6, 4))
    ax = sns.scatterplot(x='PC1', y='PC2', hue='Cluster', data=pca_df, palette='tab10', s=50, alpha=0.8)
    plt.title(plot_title)
    plt.xlabel('Principal Component 1')
    plt.ylabel('Principal Component 2')
    plt.legend(title='Cluster', frameon=False)
    plt.grid(False)
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    plt.tight_layout()
    # Save the plot
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    plt.show()

    # Optional: Print explained variance to understand the importance of each component
    print(f"Explained variance ratio for {plot_title}:", pca.explained_variance_ratio_)

# Iterate through each key in the top_genes dictionary
for gene_set_name, genes_to_score in top_genes.items():
    plot_title = f'PCA of Gene Expression Data: {gene_set_name}'
    output_file = f'PCA_plot_{gene_set_name}.png'
    process_and_plot_pca(genes_to_score, expression_matrix, plot_title, output_file)

# Display the cluster labels DataFrame
print(cluster_labels_df)

# Strip 'PCA of Gene Expression Data: ' and '_DEGs' from column names
new_columns = [col.replace('PCA of Gene Expression Data: ', '').replace('_DEGs', '') for col in cluster_labels_df.columns]
cluster_labels_df.columns = new_columns

# Display the updated cluster labels DataFrame
print(cluster_labels_df)

for col in cluster_labels_df.columns:
    # Check if the column name ends with '_score'
    if col.endswith('_score'):
        # Calculate the mean of the score column
        mean_score = cluster_labels_df[col].mean()

        # Find the corresponding label column by removing '_score'
        label_col = col.replace('_score', '')

        # Replace 1 and 0 with 'high' and 'low' based on the mean score
        cluster_labels_df[label_col] = cluster_labels_df.apply(
            lambda row: 'high' if row[col] > mean_score else 'low', axis=1
        )

# Display the updated DataFrame
#print(cluster_labels_df)

# Select columns that have '_score' at the end
columns_to_keep = [col for col in cluster_labels_df.columns if col.endswith('_score')]

# Keep only the selected columns
cluster_labels_df = cluster_labels_df[columns_to_keep]

# Display the resulting dataframe to verify
print(cluster_labels_df.shape)

# Replace 'Fibroblast_Fibroblast' with 'Fibro' in the column names
cluster_labels_df.columns = cluster_labels_df.columns.str.replace('_score', '')
cluster_labels_df.columns = cluster_labels_df.columns.str.replace('niches_', '')
# Display the updated dataframe to verify the changes
#print(cluster_labels_df)

combined_df= pd.merge(biobank, cluster_labels_df,left_index=True, right_index=True, how='inner')
#combined_df

combined_df

# Compute the Pearson correlation matrix
correlation_matrix = combined_df.corr(method='pearson')

# Display the correlation matrix
#print(correlation_matrix)

# 10 genes
plt.figure(figsize=(10, 8))
ax = sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', vmin=0)
ax.xaxis.tick_top()  # Move x-axis labels to the top
plt.xticks(rotation=90)  # Rotate the x-axis labels for better readability
plt.title('')
plt.show()

correlation_matrix.columns

correlation_matrix_subset=correlation_matrix.drop(['CD_Niche', 'CNT_Niche', 'Fibroblast_Niche',
       'Glomerular_Niche', 'Immune_Niche', 'PT_Niche', 'TAL_Niche',
       'Vascular_Niche', 'iPT_Niche', 'iTAL_Niche'], axis=1)
correlation_matrix_subset=correlation_matrix_subset.drop('Interstitium_Fibrosis', axis=0)
correlation_matrix_subset

correlation_matrix_subset.index = correlation_matrix_subset.index.str.replace('_', '\n')
correlation_matrix_subset=correlation_matrix_subset.sort_values(by='Interstitium_Fibrosis', ascending=True)
correlation_matrix_subset

plt.figure(figsize=(12, 1))
ax = sns.heatmap(correlation_matrix_subset.T, annot=True, cmap='coolwarm', fmt='.2f', vmin=-0.57, vmax=0.61)
ax.xaxis.tick_top()  # Move x-axis labels to the top
plt.xticks(rotation=90)  # Rotate the x-axis labels for better readability
plt.title('')
plt.show()

correlation_matrix_subset

import matplotlib.pyplot as plt
import seaborn as sns

# Assuming correlation_matrix_subset is your DataFrame
plt.figure(figsize=(10, 0.7))
ax = sns.heatmap(correlation_matrix_subset.T, annot=True, cmap='coolwarm', fmt='.2f', vmin=-0.57, vmax=0.61,annot_kws={"size": 10})

# Move x-axis labels to the top
ax.xaxis.tick_top()

# Rotate x-axis labels for better readability
plt.xticks(rotation=0)

# Remove y-axis and x-axis ticks
ax.tick_params(axis='both', which='both', length=0)


# Show the heatmap
plt.title('')
plt.savefig('niche_correlation_with_fibrosis_heatmap.png', dpi=450,bbox_inches='tight')
plt.show()

y_labels

combined_df.columns

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# Assuming 'combined_biobank' is your DataFrame and contains all the mentioned genes

# List of genes to plot
correlation = ['CD_Niche', 'CNT_Niche', 'Fibroblast_Niche',
       'Glomerular_Niche', 'Immune_Niche', 'PT_Niche', 'TAL_Niche',
       'Vascular_Niche', 'iPT_Niche', 'iTAL_Niche']
correlate_with = 'Interstitium_Fibrosis'  # Specify the column name for correlation

# Create scatterplots with regression line and correlation coefficient
for gene in correlation:
    plt.figure(figsize=(4, 4))  # Set the figure size for better readability
    # Create a scatter plot with a linear regression line (regplot)
    ax = sns.regplot(x=gene, y=correlate_with, data=combined_df, scatter_kws={'alpha': 1, 'color': 'black', 's': 10}, line_kws={"color": "black"}, ci=None)

    # Calculate the Pearson correlation coefficient
    correlation_coef = combined_df[gene].corr(combined_df[correlate_with])

    # Title with correlation
    plt.title(f'{gene} vs IF - Corr: {correlation_coef:.2f}')

    # Axis labels
    plt.xlabel(f'{gene}_Score')
    plt.ylabel('Interstitial Fibrosis')
    plt.savefig(f'/content/drive/MyDrive/Bernhard/Cosmx/After_Cleaning/spatial_signatures/niches/scatterplot_interstitial_fibrosis_tubules_{gene}.png', dpi=450, transparent=False)
    # Show the plot
    plt.show()

"""now with Cortex RNA"""

expression_matrix = pd.read_csv('/content/drive/MyDrive/Bernhard/BulkSeq/HK.Biobank.Cortex.TPM_n508_230928.csv', sep= ';')

expression_matrix=expression_matrix.drop('Unnamed: 0', axis=1)

expression_matrix=expression_matrix.set_index('Genes')

expression_matrix.index.name=None

expression_matrix=expression_matrix.T

expression_matrix.index = expression_matrix.index.str.rstrip('W')

expression_matrix

biobank=pd.read_csv('/content/Susztak_Lab_Biobank_122023_subset_scored.csv')

biobank=biobank.set_index('ID')

biobank=biobank.drop(['pos', 'Disease', 'GFR', 'DM', 'HTN', 'Age', 'Gender', 'Race',
       'Collection_Site', 'Height_cm', 'Weight_kg', 'BMI',
       'pct_glom_sclerosis', 'Tubules_Atrophy ',
       'Glomeruli_Total_num', 'Glomeruli_Globally Schlerotic_num',
       'Glomeruli_globally_Schlerotic_pct',
       'Glomeruli_Segmentally_Schlerotic_num', 'Glomeruli_Wall_Thickening_0_3',
       'Glomeruli_Hypoperfused_0_3', 'Glomeruli_Mesangial_Matrix_0_3',
       'Glomeruli_Mesangial_Cellularity_0_3', 'Glomeruli_KW_Nodules_0_1',
       'Glomeruli_Pericapsular_Fibrosis_0_2', 'Tubules_pct_Atrophy ',
       'Tubules_pct_Acute_Tubular_Injury', 'Tubules_Reabsorption_0_3',
       'Interstitium_Lymphocytic_Infiltrate_0_3',
       'Interstitium_Plasmacytic_Infiltrate_0_3',
       'Interstitium_Eosinophils_0_3', 'Vessels_Medial_Thickening_0_3',
       'Vessels_Intimal_Fibrosis_0_3', 'Vessels_Arteriolar_Hyalinosis_0_3'], axis=1)

biobank=biobank.astype(float)

import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans

# Assuming expression_matrix is your DataFrame containing bulk sequencing data

# Initialize an empty DataFrame to store the cluster labels
cluster_labels_df = pd.DataFrame(index=expression_matrix.index)

# Function to process and plot PCA for a given gene set
def process_and_plot_pca(genes_to_score, expression_matrix, plot_title, output_file):
    # Filter genes that are in the expression_matrix
    valid_genes = [gene for gene in genes_to_score if gene in expression_matrix.columns]
    if not valid_genes:
        print(f"No valid genes found for {plot_title}")
        return

    # Select the genes for PCA
    data = expression_matrix[valid_genes]

    # Center the data by subtracting the mean
    data_centered = data - data.mean()

    # Scale the data to the range (-1, 1)
    scaler = MinMaxScaler(feature_range=(-1, 1))
    data_scaled = scaler.fit_transform(data_centered)

    # Convert scaled data back to DataFrame for consistency
    data_scaled_df = pd.DataFrame(data_scaled, index=data.index, columns=data.columns)

    # Perform PCA
    pca = PCA(n_components=2)  # Reduce to 2 components for 2D visualization
    principal_components = pca.fit_transform(data_scaled_df)

    # Create a DataFrame with the principal components
    pca_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'], index=data.index)

    # Perform KMeans clustering
    k = 2  # Adjust based on your specific needs
    kmeans = KMeans(n_clusters=k, random_state=0)
    kmeans.fit(data_scaled_df)
    labels = kmeans.labels_

    # Add cluster labels to the PCA DataFrame
    pca_df['Cluster'] = labels

    # Add the cluster labels to the cluster_labels_df
    cluster_labels_df[plot_title] = labels
    cluster_labels_df[f'{plot_title}_score']=data_scaled_df.sum(axis=1)
    # Plot the PCA
    plt.figure(figsize=(6, 4))
    ax = sns.scatterplot(x='PC1', y='PC2', hue='Cluster', data=pca_df, palette='tab10', s=50, alpha=0.8)
    plt.title(plot_title)
    plt.xlabel('Principal Component 1')
    plt.ylabel('Principal Component 2')
    plt.legend(title='Cluster', frameon=False)
    plt.grid(False)
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    plt.tight_layout()
    # Save the plot
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    plt.show()

    # Optional: Print explained variance to understand the importance of each component
    print(f"Explained variance ratio for {plot_title}:", pca.explained_variance_ratio_)

# Iterate through each key in the top_genes dictionary
for gene_set_name, genes_to_score in top_genes.items():
    plot_title = f'PCA of Gene Expression Data: {gene_set_name}'
    output_file = f'PCA_plot_{gene_set_name}.png'
    process_and_plot_pca(genes_to_score, expression_matrix, plot_title, output_file)

# Display the cluster labels DataFrame
print(cluster_labels_df)

# Strip 'PCA of Gene Expression Data: ' and '_DEGs' from column names
new_columns = [col.replace('PCA of Gene Expression Data: ', '').replace('_DEGs', '') for col in cluster_labels_df.columns]
cluster_labels_df.columns = new_columns

# Display the updated cluster labels DataFrame
print(cluster_labels_df)

for col in cluster_labels_df.columns:
    # Check if the column name ends with '_score'
    if col.endswith('_score'):
        # Calculate the mean of the score column
        mean_score = cluster_labels_df[col].mean()

        # Find the corresponding label column by removing '_score'
        label_col = col.replace('_score', '')

        # Replace 1 and 0 with 'high' and 'low' based on the mean score
        cluster_labels_df[label_col] = cluster_labels_df.apply(
            lambda row: 'high' if row[col] > mean_score else 'low', axis=1
        )

# Display the updated DataFrame
#print(cluster_labels_df)

# Select columns that have '_score' at the end
columns_to_keep = [col for col in cluster_labels_df.columns if col.endswith('_score')]

# Keep only the selected columns
cluster_labels_df = cluster_labels_df[columns_to_keep]

# Display the resulting dataframe to verify
print(cluster_labels_df.shape)

# Replace 'Fibroblast_Fibroblast' with 'Fibro' in the column names
cluster_labels_df.columns = cluster_labels_df.columns.str.replace('_score', '')
cluster_labels_df.columns = cluster_labels_df.columns.str.replace('niches_', '')
# Display the updated dataframe to verify the changes
#print(cluster_labels_df)

combined_df= pd.merge(biobank, cluster_labels_df,left_index=True, right_index=True, how='inner')
#combined_df

# Compute the Pearson correlation matrix
correlation_matrix = combined_df.corr(method='pearson')

# Display the correlation matrix
#print(correlation_matrix)

# 10 genes
plt.figure(figsize=(10, 8))
ax = sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', vmin=0)
ax.xaxis.tick_top()  # Move x-axis labels to the top
plt.xticks(rotation=90)  # Rotate the x-axis labels for better readability
plt.title('')
plt.show()

combined_df.columns

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# Assuming 'combined_biobank' is your DataFrame and contains all the mentioned genes

# List of genes to plot
correlation = ['CD_Niche', 'CNT_Niche', 'Fibroblast_Niche',
       'Glomerular_Niche', 'Immune_Niche', 'PT_Niche', 'TAL_Niche',
       'Vascular_Niche', 'iPT_Niche', 'iTAL_Niche']
correlate_with = 'Interstitium_Fibrosis'  # Specify the column name for correlation

# Create scatterplots with regression line and correlation coefficient
for gene in correlation:
    plt.figure(figsize=(4, 4))  # Set the figure size for better readability
    # Create a scatter plot with a linear regression line (regplot)
    ax = sns.regplot(x=gene, y=correlate_with, data=combined_df, scatter_kws={'alpha': 1, 'color': 'black', 's': 10}, line_kws={"color": "black"}, ci=None)

    # Calculate the Pearson correlation coefficient
    correlation_coef = combined_df[gene].corr(combined_df[correlate_with])

    # Title with correlation
    plt.title(f'{gene} vs IF - Corr: {correlation_coef:.2f}')

    # Axis labels
    plt.xlabel(f'{gene}_Score')
    plt.ylabel('Interstitial Fibrosis')
    plt.savefig(f'/content/drive/MyDrive/Bernhard/Cosmx/After_Cleaning/spatial_signatures/niches/scatterplot_interstitial_fibrosis_cortex_{gene}.png', dpi=450, transparent=False)
    # Show the plot
    plt.show()



"""now with glomseq"""

import pandas as pd
expression_matrix = pd.read_csv('/content/drive/MyDrive/Bernhard/BulkSeq/Glom_Bulk_Seq_HK.txt', sep= '\t')

gene_information = pd.read_csv('/content/drive/MyDrive/Bernhard/BulkSeq/gene_information.txt', sep= '\t')

gene_information['ensmbl']

gene_information

gene_dict = pd.Series(gene_information.symbol.values, index=gene_information.ensmbl_v).to_dict()

# Extract the Gene IDs without the version numbers
expression_matrix['Gene_ID_Base'] = expression_matrix['Gene_ID'].str.split('.').str[0]

# Map the gene names onto the expression matrix
expression_matrix['Gene_Name'] = expression_matrix['Gene_ID'].map(gene_dict)

# Display the first few rows to ensure it was processed correctly
print(expression_matrix.head())

gene_dict = pd.Series(gene_information.symbol.values, index=gene_information.ensmbl).to_dict()

# Map the gene names onto the expression matrix
expression_matrix['Gene_Name_2'] = expression_matrix['Gene_ID_Base'].map(gene_dict)

# Display the first few rows to ensure it was processed correctly
print(expression_matrix.head())

expression_matrix.drop(['Gene_ID_Base', 'Gene_Name', 'Gene_ID'], axis=1)
expression_matrix

expression_matrix=expression_matrix.drop('Gene_ID', axis=1)

expression_matrix

expression_matrix=expression_matrix.set_index('Gene_Name_2')

expression_matrix.index.name=None

expression_matrix=expression_matrix.T

expression_matrix.index = expression_matrix.index.str.rstrip('G')

expression_matrix

biobank=pd.read_csv('/content/Susztak_Lab_Biobank_122023_subset_scored.csv')

biobank=biobank.set_index('ID')

biobank=biobank.drop(['pos', 'Disease', 'GFR', 'DM', 'HTN', 'Age', 'Gender', 'Race',
       'Collection_Site', 'Height_cm', 'Weight_kg', 'BMI',
       'pct_glom_sclerosis', 'Tubules_Atrophy ',
       'Glomeruli_Total_num', 'Glomeruli_Globally Schlerotic_num',
       'Glomeruli_Segmentally_Schlerotic_num', 'Glomeruli_Wall_Thickening_0_3',
       'Glomeruli_Hypoperfused_0_3', 'Glomeruli_Mesangial_Matrix_0_3',
       'Glomeruli_Mesangial_Cellularity_0_3', 'Glomeruli_KW_Nodules_0_1',
       'Glomeruli_Pericapsular_Fibrosis_0_2', 'Tubules_pct_Atrophy ',
       'Tubules_pct_Acute_Tubular_Injury', 'Tubules_Reabsorption_0_3',
       'Interstitium_Lymphocytic_Infiltrate_0_3',
       'Interstitium_Plasmacytic_Infiltrate_0_3',
       'Interstitium_Eosinophils_0_3', 'Vessels_Medial_Thickening_0_3',
       'Vessels_Intimal_Fibrosis_0_3', 'Vessels_Arteriolar_Hyalinosis_0_3'], axis=1)

biobank=biobank.drop(['HK2456', 'HK2770','HK2430', 'HK2739', 'HK2494', 'HK17', 'HK84', 'HK2412', 'HK2441'], axis=0)

#biobank=biobank.drop(['HK344'], axis=0)
biobank=biobank.drop(['HK2379'], axis=0)

biobank

biobank['Glomeruli_globally_Schlerotic_pct'].dtype

biobank=biobank.astype(str)

biobank.shape

biobank=biobank[biobank['Glomeruli_globally_Schlerotic_pct']!='\xa0']
biobank.shape

biobank=biobank.astype(float)
biobank

expression_matrix=expression_matrix.drop(['Gene_ID_Base', 'Gene_Name'], axis=0)

expression_matrix=expression_matrix.astype(float)

import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans

# Assuming expression_matrix is your DataFrame containing bulk sequencing data

# Initialize an empty DataFrame to store the cluster labels
cluster_labels_df = pd.DataFrame(index=expression_matrix.index)

# Function to process and plot PCA for a given gene set
def process_and_plot_pca(genes_to_score, expression_matrix, plot_title, output_file):
    # Filter genes that are in the expression_matrix
    valid_genes = [gene for gene in genes_to_score if gene in expression_matrix.columns]
    if not valid_genes:
        print(f"No valid genes found for {plot_title}")
        return

    # Select the genes for PCA
    data = expression_matrix[valid_genes]

    # Center the data by subtracting the mean
    data_centered = data - data.mean()

    # Scale the data to the range (-1, 1)
    scaler = MinMaxScaler(feature_range=(-1, 1))
    data_scaled = scaler.fit_transform(data_centered)

    # Convert scaled data back to DataFrame for consistency
    data_scaled_df = pd.DataFrame(data_scaled, index=data.index, columns=data.columns)

    # Perform PCA
    pca = PCA(n_components=2)  # Reduce to 2 components for 2D visualization
    principal_components = pca.fit_transform(data_scaled_df)

    # Create a DataFrame with the principal components
    pca_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'], index=data.index)

    # Perform KMeans clustering
    k = 2  # Adjust based on your specific needs
    kmeans = KMeans(n_clusters=k, random_state=0)
    kmeans.fit(data_scaled_df)
    labels = kmeans.labels_

    # Add cluster labels to the PCA DataFrame
    pca_df['Cluster'] = labels

    # Add the cluster labels to the cluster_labels_df
    cluster_labels_df[plot_title] = labels
    cluster_labels_df[f'{plot_title}_score']=data_scaled_df.sum(axis=1)
    # Plot the PCA
    plt.figure(figsize=(6, 4))
    ax = sns.scatterplot(x='PC1', y='PC2', hue='Cluster', data=pca_df, palette='tab10', s=50, alpha=0.8)
    plt.title(plot_title)
    plt.xlabel('Principal Component 1')
    plt.ylabel('Principal Component 2')
    plt.legend(title='Cluster', frameon=False)
    plt.grid(False)
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    plt.tight_layout()
    # Save the plot
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    plt.show()

    # Optional: Print explained variance to understand the importance of each component
    print(f"Explained variance ratio for {plot_title}:", pca.explained_variance_ratio_)

# Iterate through each key in the top_genes dictionary
for gene_set_name, genes_to_score in top_genes.items():
    plot_title = f'PCA of Gene Expression Data: {gene_set_name}'
    output_file = f'PCA_plot_{gene_set_name}.png'
    process_and_plot_pca(genes_to_score, expression_matrix, plot_title, output_file)

# Display the cluster labels DataFrame
print(cluster_labels_df)

# Strip 'PCA of Gene Expression Data: ' and '_DEGs' from column names
new_columns = [col.replace('PCA of Gene Expression Data: ', '').replace('_DEGs', '') for col in cluster_labels_df.columns]
cluster_labels_df.columns = new_columns

# Display the updated cluster labels DataFrame
print(cluster_labels_df)

for col in cluster_labels_df.columns:
    # Check if the column name ends with '_score'
    if col.endswith('_score'):
        # Calculate the mean of the score column
        mean_score = cluster_labels_df[col].mean()

        # Find the corresponding label column by removing '_score'
        label_col = col.replace('_score', '')

        # Replace 1 and 0 with 'high' and 'low' based on the mean score
        cluster_labels_df[label_col] = cluster_labels_df.apply(
            lambda row: 'high' if row[col] > mean_score else 'low', axis=1
        )

# Display the updated DataFrame
#print(cluster_labels_df)

# Select columns that have '_score' at the end
columns_to_keep = [col for col in cluster_labels_df.columns if col.endswith('_score')]

# Keep only the selected columns
cluster_labels_df = cluster_labels_df[columns_to_keep]

# Display the resulting dataframe to verify
print(cluster_labels_df.shape)

# Replace 'Fibroblast_Fibroblast' with 'Fibro' in the column names
cluster_labels_df.columns = cluster_labels_df.columns.str.replace('_score', '')
cluster_labels_df.columns = cluster_labels_df.columns.str.replace('niches_', '')
# Display the updated dataframe to verify the changes
#print(cluster_labels_df)

combined_df= pd.merge(biobank, cluster_labels_df,left_index=True, right_index=True, how='inner')
#combined_df

# Compute the Pearson correlation matrix
correlation_matrix = combined_df.corr(method='pearson')

# Display the correlation matrix
#print(correlation_matrix)

# 10 genes
plt.figure(figsize=(10, 8))
ax = sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', vmin=0)
ax.xaxis.tick_top()  # Move x-axis labels to the top
plt.xticks(rotation=90)  # Rotate the x-axis labels for better readability
plt.title('')
plt.show()

combined_df.columns

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# Assuming 'combined_biobank' is your DataFrame and contains all the mentioned genes

# List of genes to plot
correlation = [
       'Glomerular_Niche']
correlate_with = 'Interstitium_Fibrosis'  # Specify the column name for correlation

# Create scatterplots with regression line and correlation coefficient
for gene in correlation:
    plt.figure(figsize=(4, 4))  # Set the figure size for better readability
    # Create a scatter plot with a linear regression line (regplot)
    ax = sns.regplot(x=gene, y=correlate_with, data=combined_df, scatter_kws={'alpha': 1, 'color': 'black', 's': 10}, line_kws={"color": "black"}, ci=None)

    # Calculate the Pearson correlation coefficient
    correlation_coef = combined_df[gene].corr(combined_df[correlate_with])

    # Title with correlation
    plt.title(f'{gene} vs IF - Corr: {correlation_coef:.2f}')

    # Axis labels
    plt.xlabel(f'{gene}_Score')
    plt.ylabel('Interstitial Fibrosis')
    plt.savefig(f'/content/drive/MyDrive/Bernhard/Cosmx/After_Cleaning/spatial_signatures/niches/scatterplot_interstitial_fibrosis_gloms_{gene}.png', dpi=450, transparent=False)
    # Show the plot
    plt.show()