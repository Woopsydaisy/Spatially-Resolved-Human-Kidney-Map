# -*- coding: utf-8 -*-
"""Neighborhood generation immune Subcluster and figure kmeans Volume 2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fk4ShlhpkV35RrOWrLasDvNs-nf6-RRS
"""

!pip --quiet install scanpy
!pip --quiet install leidenalg
#!pip --quiet install squidpy

from google.colab import drive
drive.mount('/content/drive')

import csv
import anndata as ad
import gzip
import os
import scipy.io
import scanpy as sc
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from google.colab import drive
import leidenalg as la
from pathlib import Path
#import squidpy as sq

adata = sc.read_h5ad('/content/drive/MyDrive/Bernhard/Cosmx/After_Cleaning/all_Cosmx_cleaned_neighbored.h5ad')

adata.obs['immune_subcluster_ME_20um'].value_counts()



adata_all=sc.read_h5ad('/content/drive/MyDrive/Bernhard/Cosmx/SCVI/All_Runs/allCosmx_allGenes.h5ad')

adata_all.obs['immune_subcluster_ME']=adata.obs['immune_subcluster_ME'].copy()

"""lets try again with clustering the dataframe with neighborfractions"""

new_adata_2=sc.read_h5ad('/content/drive/MyDrive/Bernhard/Cosmx/After_Cleaning/neighbors_as_genes_all_cosmx.h5ad')

new_adata=sc.read_h5ad('/content/drive/MyDrive/Bernhard/Cosmx/After_Cleaning/neighbors_as_genes_all_cosmx_immune_subcluster.h5ad')

new_adata.obs['total_neighbors_200']=new_adata_2.obs['total_neighbors_200'].copy()

new_adata.obs['immune_subcluster_ME']=adata.obs['immune_subcluster_ME'].copy()

new_adata_subset=new_adata[new_adata.obs['total_neighbors_200']>50]
new_adata_subset

new_adata_subset=new_adata_subset[new_adata_subset.obs['annotation_post_scanvi70_broad']=='Immune']
new_adata_subset

print(new_adata_subset.obs['annotation_post_scanvi70_broad'].value_counts())

import pandas as pd

# Convert the sparse matrix to a dense format and create a DataFrame
gene_expression_df = pd.DataFrame(
    new_adata_subset.X.toarray(),
    index=new_adata_subset.obs_names,
    columns=new_adata_subset.var_names
)

# Print the first few rows to verify
print(gene_expression_df.head())

# List of .obs columns you want to add to the DataFrame
obs_columns = [
    'total_neighbors_80', 'total_neighbors_60', 'total_neighbors_40', 'total_neighbors_20'
]

# Add the selected .obs columns to the gene expression DataFrame
gene_expression_df[obs_columns] = new_adata_subset.obs[obs_columns]

# Print the first few rows to verify the updated DataFrame
#print(gene_expression_df.head())

# Loop over each suffix and corresponding total_neighbors column
for neighbors in [80, 60, 40, 20]:
    # Generate the suffix and obs column name
    suffix = f'_{neighbors}'
    obs_column = f'total_neighbors_{neighbors}'

    # Get all columns that end with the current suffix
    matching_columns = [col for col in gene_expression_df.columns if col.endswith(suffix)]

    # Perform the division for each matching column
    for col in matching_columns:
        gene_expression_df[col] /= gene_expression_df[obs_column]

# Print the first few rows to verify the updated DataFrame
#print(gene_expression_df.head())

gene_expression_df = gene_expression_df.drop(obs_columns, axis=1)

# Print the first few rows to verify that columns are removed
print(gene_expression_df.head())

import numpy as np

# Replace infinite values with 0
gene_expression_df.replace([np.inf, -np.inf], 0, inplace=True)

# Verify changes by displaying the first few rows of the DataFrame
print(gene_expression_df.head())

gene_expression_df=gene_expression_df.fillna(0)

delete_suffixes = ['200', '180', '160', '140', '120', '100']

# Filter out columns that end with the specified suffixes
columns_to_keep = [col for col in gene_expression_df.columns if not any(col.endswith(suffix) for suffix in delete_suffixes)]
filtered_df = gene_expression_df[columns_to_keep]
print(filtered_df.shape)

print(filtered_df.columns)

prefixes_to_remove = [
    'TAL', 'PT',  'IC B', 'PC', 'DTL_ATL',
    'EC_Peritub', 'Immune', 'EC_DVR', 'VSMC', 'DCT',
    'CNT', 'Podo', 'EC_glom', 'PEC', 'IC A', 'MC1', 'Macro III', 'Macro IV', 'cycling Lymphocytes'
]

# Create a list of columns to drop
columns_to_drop = [col for col in filtered_df.columns if any(col.startswith(prefix) for prefix in prefixes_to_remove)]

# Drop the columns
filtered_df = filtered_df.drop(columns=columns_to_drop)

print(filtered_df.columns)

filtered_df

from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

scaler = StandardScaler()
features_normalized = scaler.fit_transform(filtered_df)

pca = PCA()
principal_components = pca.fit_transform(features_normalized)

# Create a scree plot
explained_variance = pca.explained_variance_ratio_
cumulative_variance = np.cumsum(explained_variance)

plt.figure(figsize=(10, 6))
plt.plot(range(1, len(explained_variance) + 1), explained_variance, marker='o', linestyle='--', label='Individual explained variance')
plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, marker='o', label='Cumulative explained variance')
plt.axhline(y=0.95, color='r', linestyle='--', label='95% explained variance')
plt.title('Scree Plot')
plt.xlabel('Principal Component')
plt.ylabel('Explained Variance Ratio')
plt.legend()
plt.grid()
plt.show()

import pandas as pd
import numpy as np
from sklearn.cluster import MiniBatchKMeans, AgglomerativeClustering
from scipy.cluster.hierarchy import dendrogram, linkage
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
import umap.umap_ as umap
from sklearn.decomposition import PCA

# Assuming your dataframe is already loaded as gene_expression_df
# Normalize the data
scaler = StandardScaler()
features_normalized = scaler.fit_transform(filtered_df)

pca = PCA(n_components=15)  # Reduce to 10 dimensions for UMAP input
principal_components = pca.fit_transform(features_normalized)

from sklearn.cluster import MiniBatchKMeans
from sklearn.metrics import silhouette_score

inertias = []
k = range(1, 10)

# dissimilarity would not be defined for a single cluster, thus, minimum number of clusters should be 2
for K in k:
    # Create a MiniBatchKMeans object, arbitrarily choosing 10 clusters
    kmeans = MiniBatchKMeans(n_clusters=K)
    # Fit the model to the data
    kmeans.fit(principal_components)
    inertias.append(kmeans.inertia_)

plt.plot(k, inertias, 'bx-')
plt.xlabel('Values of K')
plt.ylabel('Inertia')
plt.title('The Elbow Method using Inertia')
plt.show()

# Perform MiniBatchKMeans clustering
kmeans = MiniBatchKMeans(n_clusters=6, random_state=42)
labels = kmeans.fit_predict(principal_components)
filtered_df['cluster_labels'] = labels

new_adata_subset.obs['cluster_labels']=filtered_df['cluster_labels'].copy()

print(new_adata_subset.obs['cluster_labels'])

new_adata_subset.obs['cluster_labels']=new_adata_subset.obs['cluster_labels'].astype('category')

new_adata_subset

delete_suffixes = ['80', '60', '40', '20']

# Filter out columns that end with the specified suffixes
columns_to_keep = [col for col in gene_expression_df.columns if not any(col.endswith(suffix) for suffix in delete_suffixes)]
filtered_df_new = gene_expression_df.copy()
filtered_df_new[columns_to_keep]=0
print(filtered_df_new)

from scipy import sparse
sparse_matrix = scipy.sparse.csr_matrix(gene_expression_df.values)
new_adata_subset.X=sparse_matrix

sc.tl.rank_genes_groups(new_adata_subset, groupby='cluster_labels', method='wilcoxon', pts = True)
sc.pl.rank_genes_groups(new_adata_subset, n_genes=25, sharey=False)

new_adata_subset.obs["cluster_labels"].value_counts()
cell_identities = {0: 'Immune ME 1', 1: 'Immune ME 2', 2: 'Immune ME 3', 3: 'Immune ME 4',4: 'Immune ME 5', 5: 'Immune ME 6',}
new_adata_subset.obs["cluster_labels_annotated_immune"] = new_adata_subset.obs['cluster_labels'].map(cell_identities).astype('category')

new_adata_subset.obs["cluster_labels_annotated_immune"].value_counts()

de_results = new_adata_subset.uns['rank_genes_groups']
for group in de_results['names'].dtype.names:
        gene_names = de_results['names'][group]
        gene_scores = de_results['scores'][group]
        gene_logfoldchanges = de_results['logfoldchanges'][group]
        gene_pvals = de_results['pvals'][group]
        gene_pvals_adj = de_results['pvals_adj'][group]

        # Create a DataFrame
        df = pd.DataFrame({
            'Gene': gene_names,
            'Score': gene_scores,
            'LogFoldChange': gene_logfoldchanges,
            'pValue': gene_pvals,
            'pValue_adj': gene_pvals_adj
        })
        df=df[df['LogFoldChange']>0]
        df=df[df['pValue_adj']<0.01]
        df = df[~df['Gene'].str.endswith('_200')]
        df = df[~df['Gene'].str.endswith('_180')]
        df = df[~df['Gene'].str.endswith('_160')]
        df = df[~df['Gene'].str.endswith('_140')]
        df = df[~df['Gene'].str.endswith('_120')]
        df = df[~df['Gene'].str.endswith('_100')]
        df = df[~df['Gene'].str.endswith('_80')]

        print(df.head(40))

filtered_df.head(10)

cell_colors = {
    'PC': (0.12156862745098039, 0.4666666666666667, 0.7058823529411765),
    'CNT': (0.6823529411764706, 0.7803921568627451, 0.9098039215686274),
    'DCT': (1.0, 0.4980392156862745, 0.054901960784313725),
    'DTL_ATL': (1.0, 0.7333333333333333, 0.47058823529411764),
    'EC_DVR': (0.17254901960784313, 0.6274509803921569, 0.17254901960784313),
    'EC_Peritub': (0.596078431372549, 0.8745098039215686, 0.5411764705882353),
    'EC_glom': (0.8392156862745098, 0.15294117647058825, 0.1568627450980392),
    'IC A': (1.0, 0.596078431372549, 0.5882352941176471),
    'IC B': (0.5803921568627451, 0.403921568627451, 0.7411764705882353),
    'Immune': (0.7725490196078432, 0.6901960784313725, 0.8352941176470589),
    'Podo': (0.5490196078431373, 0.33725490196078434, 0.29411764705882354),
    'Fibroblast': (0.7686274509803922, 0.611764705882353, 0.5803921568627451),
    'PEC': (0.8901960784313725, 0.4666666666666667, 0.7607843137254902),
    'PT': (0.9686274509803922, 0.7137254901960784, 0.8235294117647058),
    'MC1': (0.4980392156862745, 0.4980392156862745, 0.4980392156862745),
    'iPT': (0.7803921568627451, 0.7803921568627451, 0.7803921568627451),
    'iTAL': (0.8588235294117647, 0.8588235294117647, 0.5529411764705883),
    'TAL': (0.09019607843137255, 0.7450980392156863, 0.8117647058823529),
    'VSMC': (0.6196078431372549, 0.8549019607843137, 0.8980392156862745),
    'CD4+': (0.5529411764705883, 0.8274509803921568, 0.7803921568627451),
    'Baso/Mast': (0.2235, 0.2314, 0.4745),
    'B': (0.7450980392156863, 0.7294117647058823, 0.8549019607843137),
    'CD8+ I': (0.6784, 0.2863, 0.2902),
    'Macro II': (0.9921568627450981, 0.7058823529411765, 0.3843137254901961),
    'Neutrophil': (0.9882352941176471, 0.803921568627451, 0.8980392156862745),
    'Macro I': (0.3, 0.3, 0.3),
    'NK': (0.7372549019607844, 0.5019607843137255, 0.7411764705882353),
    'cDC': (0.9176470588235294, 0.5019607843137255, 0.23529411764705882),
    'mDC': (0.34509803921568627, 0.33725490196078434, 0.6745098039215687),
    'pDC': (0.6509803921568628, 0.4627450980392157, 0.11372549019607843),
    'Macro III': (0.9294117647058824, 0.6941176470588235, 0.12549019607843137),
    'Macro IV': (0.41568627450980394, 0.23921568627450981, 0.6039215686274509),
    'cycling Lymphocytes': (0.8, 0.47058823529411764, 0.7372549019607844),
    'CD8+ II': (0.9921568627450981, 0.7529411764705882, 0.5254901960784314),
    'Plasma': (0.2196078431372549, 0.4235294117647059, 0.6901960784313725),
    'other':(0.5,0.5,0.5,0.5)
    #'cytotox B': (0.4, 0.7607843137254902, 0.6470588235294118)
    }

filtered_df['cluster_labels']=new_adata_subset.obs['cluster_labels_annotated_immune'].copy()

filtered_df

import pandas as pd
import matplotlib.pyplot as plt

# Assuming filtered_df is your dataframe
# Step 1: Filter columns that end with '_20'
columns_to_keep = [col for col in filtered_df.columns if col.endswith('_20')]
columns_to_keep.append('cluster_labels')  # Make sure to keep the 'cluster_labels' column

filtered_20_df = filtered_df[columns_to_keep]

# Step 2: Rename the columns to remove the '_20' suffix
filtered_20_df.columns = [col[:-3] if col.endswith('_20') else col for col in filtered_20_df.columns]

# Step 3: Group by 'cluster_labels' and sum the values for each group
grouped_df = filtered_20_df.groupby('cluster_labels').sum()

# Step 4: Normalize the grouped values so that each bar equals 1
normalized_df = grouped_df.div(grouped_df.sum(axis=1), axis=0)

# Map the colors to the columns
colors = [cell_colors.get(col, 'grey') for col in normalized_df.columns]

# Step 5: Plot the stacked bar plot
plt.figure(figsize=(8, 8))
ax = normalized_df.plot(kind='bar', stacked=True, color=colors, figsize=(12, 8))

# Add labels and title
plt.xlabel('Cluster Labels')
plt.ylabel('Proportion')
plt.title('20um Neighborhood by Immune Cluster Labels')
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['left'].set_visible(False)
ax.spines['bottom'].set_visible(False)
plt.tick_params(axis='x', which='both', length=0)
plt.tick_params(axis='y', which='both', length=0)
# Adjust layout and move the legend below the plot
plt.legend(title='', bbox_to_anchor=(0.5, -0.15), loc='upper center', ncol=6, frameon=False)
plt.tight_layout()
plt.savefig('Immune Cluster 20um immune neighbors.png', dpi=450, bbox_inches='tight')
# Show the plot
plt.show()



"""increase in DKD"""

adata.obs['immune_subcluster_ME']=new_adata_subset.obs["cluster_labels_annotated_immune"].copy()
adata.obs['immune_subcluster_ME'] = adata.obs['immune_subcluster_ME'].cat.add_categories(['outlier'])
adata.obs["immune_subcluster_ME"]=adata.obs["immune_subcluster_ME"].fillna('outlier')
print(adata.obs['immune_subcluster_ME'])

print(adata.obs['immune_subcluster_ME'].value_counts())

adata_subset=adata[adata.obs['immune_subcluster_ME']!='outlier']

palette={
    'Immune ME 1': '#007ABA',
    'Immune ME 2': '#EE7402',
    'Immune ME 3': '#E4051E',
    'Immune ME 4': '#8F65A8',
    'Immune ME 5': '#BBBE09',
    'Immune ME 6': '#00AFC5',
}##'#92D2DF',

import matplotlib.pyplot as plt
import seaborn as sns

# Assuming new_adata_subset is your AnnData object
# Extract the relevant columns
samples = adata_subset.obs['sample']
cluster_labels = adata_subset.obs['immune_subcluster_ME']

# Create a DataFrame from the relevant columns
data = pd.DataFrame({'sample': samples, 'immune_subcluster_ME': cluster_labels})

# Group by 'sample' and 'cluster_labels_annotated' and count the occurrences
grouped_data = data.groupby(['sample', 'immune_subcluster_ME']).size().unstack(fill_value=0)
desired_order = [
    "Pediatric1", "HK2753", "HK3039", "HK3106", "HK3531", "HK3531_2",
    "HK3063", "HK3542", "HK2874", "HK2695", "HK3035", "HK3035_2",
     "HK2841", "HK2873","HK2844", "HK2844_2"
]

grouped_data=grouped_data.reindex(desired_order)
sample_totals = data['sample'].value_counts()
sample_totals=sample_totals.reindex(desired_order)
normalized_count_df = grouped_data.div(sample_totals, axis='index')
colors = [palette[col] for col in normalized_count_df.columns]
ax = normalized_count_df.plot(kind='bar', stacked=True, figsize=(7, 4), color=colors)

# Set plot labels and title
plt.xlabel('')
plt.ylabel('Relative Amount')
plt.title('')
plt.legend(title='', bbox_to_anchor=(0.5, 0.95), loc='lower center',ncol=4, frameon=False)
plt.tick_params(axis='x', which='both', length=0)
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
plt.tight_layout()
plt.savefig('immune ME vol 2 relative niche amount less less less longer.png', dpi=450, bbox_inches='tight')
plt.show()

adata_subset

import matplotlib.pyplot as plt
import seaborn as sns

# Assuming new_adata_subset is your AnnData object
# Extract the relevant columns
samples = adata_subset.obs['immune_subcluster_ME']
cluster_labels = adata_subset.obs['immune_cell_update']

# Create a DataFrame from the relevant columns
data = pd.DataFrame({'immune_subcluster_ME': samples, 'immune_cell_update': cluster_labels})
# Group by 'sample' and 'cluster_labels_annotated' and count the occurrences
grouped_data = data.groupby(['immune_subcluster_ME', 'immune_cell_update']).size().unstack(fill_value=0)
grouped_data=grouped_data.drop(['Macro III', 'Macro IV', 'cycling Lymphocytes'], axis=1)

desired_order = [
    "Pediatric1", "HK2753", "HK3039", "HK3106", "HK3531", "HK3531_2",
    "HK3063", "HK3542", "HK2874", "HK2695", "HK3035", "HK3035_2",
     "HK2841", "HK2873","HK2844", "HK2844_2"
]

#grouped_data=grouped_data.reindex(desired_order)
sample_totals = data['immune_subcluster_ME'].value_counts()
#sample_totals=sample_totals.reindex(desired_order)
normalized_count_df = grouped_data.div(sample_totals, axis='index')
colors = [cell_colors[col] for col in normalized_count_df.columns]
ax = normalized_count_df.plot(kind='bar', stacked=True, figsize=(6, 8), color=colors)

# Set plot labels and title
plt.xlabel('')
plt.ylabel('Relative Amount')
plt.title('')
plt.legend(title='', bbox_to_anchor=(0.5, 0.95), loc='lower center',ncol=5, frameon=False)
plt.tick_params(axis='x', which='both', length=0)
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['left'].set_visible(False)
ax.spines['bottom'].set_visible(False)
plt.tight_layout()
plt.savefig('immune composition.png', dpi=450, bbox_inches='tight')
plt.show()

grouped_data

import matplotlib.pyplot as plt
import pandas as pd

# Assuming new_adata_subset is your AnnData object
# Extract the relevant columns
samples = adata_subset.obs['immune_subcluster_ME']
cluster_labels = adata_subset.obs['immune_cell_update']

# Create a DataFrame from the relevant columns
data = pd.DataFrame({'immune_subcluster_ME': samples, 'immune_cell_update': cluster_labels})
# Group by 'sample' and 'cluster_labels_annotated' and count the occurrences
grouped_data = data.groupby(['immune_subcluster_ME', 'immune_cell_update']).size().unstack(fill_value=0)
grouped_data = grouped_data.drop(['Macro III', 'Macro IV', 'cycling Lymphocytes'], axis=1)
colors = [cell_colors.get(col, 'grey') for col in grouped_data.columns]
# Plot pie charts for each subcluster
for subcluster in grouped_data.index:
    subcluster_data = grouped_data.loc[subcluster]
    print(subcluster)
    # Plot pie chart
    plt.figure(figsize=(6, 6))
    plt.pie(subcluster_data, startangle=0, colors=colors)
    plt.title(f'')
    plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
    plt.savefig(f'Pie Chart {subcluster} inner circle.png', dpi=450, bbox_inches='tight')
    plt.show()

import matplotlib.pyplot as plt
import pandas as pd

# Assuming new_adata_subset is your AnnData object
# Extract the relevant columns
samples = adata_subset.obs['immune_subcluster_ME']
cluster_labels = adata_subset.obs['immune_cell_update']

# Create a DataFrame from the relevant columns
data = pd.DataFrame({'immune_subcluster_ME': samples, 'immune_cell_update': cluster_labels})
# Group by 'sample' and 'cluster_labels_annotated' and count the occurrences
grouped_data = data.groupby(['immune_subcluster_ME', 'immune_cell_update']).size().unstack(fill_value=0)
grouped_data = grouped_data.drop(['Macro III', 'Macro IV', 'cycling Lymphocytes'], axis=1)

colors = [cell_colors.get(col, 'grey') for col in grouped_data.columns]

# Plot pie charts for each subcluster
for subcluster in grouped_data.index:
    subcluster_data = grouped_data.loc[subcluster]
    colors = [cell_colors.get(cell, 'grey') for cell in subcluster_data.index]

    # Plot pie chart
    plt.figure(figsize=(6, 6))
    wedges, texts, autotexts = plt.pie(subcluster_data, startangle=0, colors=colors, autopct='%1.1f%%')

    # Create a custom legend
    plt.legend(wedges, subcluster_data.index, title="Center Cells", loc="center left", bbox_to_anchor=(1, 0, 0.5, 1), ncol=1, frameon=False,labelspacing=1.5)

    plt.title(f'Immune Cell Composition in {subcluster}')
    plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
    plt.savefig(f'Legend_Pie Chart {subcluster} inner circle.png', dpi=450, bbox_inches='tight')
    plt.show()

subcluster_data

for sample in adata.obs['sample'].unique():
  subset=adata[adata.obs['sample']==sample]
  sc.pl.scatter(
    subset,
    x="CenterX_global_px",
    y="CenterY_global_px",
    color="immune_subcluster_ME",
    size=3,
    title=f'immune_subcluster_ME {sample}',
  )

df = pd.DataFrame({
    'cluster_labels': adata.obs['immune_subcluster_ME'],
    'type': adata.obs['type'],
    'sample':adata.obs['sample']
}, index=adata.obs_names)
df

df=df[df['cluster_labels']!='outlier']

df['type']=df['type'].replace('Pediatric', 'Healthy')

df['type'].value_counts()

df=df[df['type']!='Diabetes']
df['sample'].value_counts()

df=df[df['sample']!='HK2874']

df['sample'].value_counts()

df

df=df.drop('sample', axis=1)

df['type'] = df['type'].cat.remove_unused_categories()

df['cluster_labels'] = df['cluster_labels'].cat.remove_unused_categories()

# Step 1: Group by 'type' and 'cluster_labels' and count the occurrences
grouped_counts = df.groupby(['type', 'cluster_labels']).size().reset_index(name='count')

# Step 2: Calculate the total number of 'cluster_labels' for each 'type'
total_counts = df.groupby('type').size().reset_index(name='total_count')

# Step 3: Merge the total counts back to the grouped counts
merged_counts = pd.merge(grouped_counts, total_counts, on='type')

# Step 4: Normalize the counts by the total counts for each 'type'
merged_counts['normalized_count'] = merged_counts['count'] / merged_counts['total_count']

# Step 5: Display the result
print(merged_counts)

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Assuming 'merged_counts' is your DataFrame
# Split the DataFrame into Healthy and Disease
healthy_df = merged_counts[merged_counts['type'] == 'Healthy']
disease_df = merged_counts[merged_counts['type'] == 'Disease']

# Merge Healthy and Disease dataframes on 'cluster_labels'
merged = pd.merge(healthy_df, disease_df, on='cluster_labels', suffixes=('_healthy', '_disease'))

# Calculate the relative increase
merged['relative_increase'] = (merged['normalized_count_disease'] - merged['normalized_count_healthy']) / merged['normalized_count_healthy']
heatmap_data = merged.set_index('cluster_labels')[['relative_increase']]
heatmap_data_rounded = heatmap_data.round(0).astype(int)
heatmap_data_rounded=heatmap_data_rounded.T
heatmap_data_rounded.columns = heatmap_data_rounded.columns.str.replace('Immune ', '')
# Plotting the heatmap
plt.figure(figsize=(5, 1))
ax = sns.heatmap(heatmap_data_rounded, annot=True, cmap='magma',fmt='d',cbar=False, vmax=30)
#ax.set_xticks([])
ax.tick_params(axis='y', which='both', left=False, right=False)
# Add labels and title
plt.xlabel('')
plt.ylabel('')
plt.tick_params(axis='x', which='both', length=0)
plt.tick_params(axis='y', which='both', length=0)
plt.title('')

# Save the plot
plt.tight_layout()
plt.savefig('relative_increase_immune_heatmap.png', dpi=450)
plt.show()

heatmap_data_rounded

adata

adata.write('/content/drive/MyDrive/Bernhard/Cosmx/After_Cleaning/all_Cosmx_cleaned_neighbored.h5ad')

new_adata_2.obs['immune_subcluster_ME']=adata.obs['immune_subcluster_ME'].copy()

new_adata_subset=new_adata_2[new_adata_2.obs['immune_subcluster_ME']!='outlier']

import pandas as pd

# Convert the sparse matrix to a dense format and create a DataFrame
gene_expression_df = pd.DataFrame(
    new_adata_subset.X.toarray(),
    index=new_adata_subset.obs_names,
    columns=new_adata_subset.var_names
)

# Print the first few rows to verify
print(gene_expression_df.head())

# List of .obs columns you want to add to the DataFrame
obs_columns = [
    'total_neighbors_80', 'total_neighbors_60', 'total_neighbors_40', 'total_neighbors_20'
]

# Add the selected .obs columns to the gene expression DataFrame
gene_expression_df[obs_columns] = new_adata_subset.obs[obs_columns]

# Print the first few rows to verify the updated DataFrame
print(gene_expression_df.head())

# Loop over each suffix and corresponding total_neighbors column
for neighbors in [80, 60, 40, 20]:
    # Generate the suffix and obs column name
    suffix = f'_{neighbors}'
    obs_column = f'total_neighbors_{neighbors}'

    # Get all columns that end with the current suffix
    matching_columns = [col for col in gene_expression_df.columns if col.endswith(suffix)]

    # Perform the division for each matching column
    for col in matching_columns:
        gene_expression_df[col] /= gene_expression_df[obs_column]

# Print the first few rows to verify the updated DataFrame
print(gene_expression_df.head())

gene_expression_df = gene_expression_df.drop(obs_columns, axis=1)

# Print the first few rows to verify that columns are removed
print(gene_expression_df.head())

import numpy as np

# Replace infinite values with 0
gene_expression_df.replace([np.inf, -np.inf], 0, inplace=True)

# Verify changes by displaying the first few rows of the DataFrame
print(gene_expression_df.head())

gene_expression_df=gene_expression_df.fillna(0)

delete_suffixes = ['200', '180', '160', '140', '120', '100']

# Filter out columns that end with the specified suffixes
columns_to_keep = [col for col in gene_expression_df.columns if not any(col.endswith(suffix) for suffix in delete_suffixes)]
filtered_df = gene_expression_df[columns_to_keep]
print(filtered_df.shape)

filtered_df['cluster_labels']=new_adata_subset.obs['immune_subcluster_ME'].copy()

filtered_df

import pandas as pd
import matplotlib.pyplot as plt

# Assuming filtered_df is your dataframe
# Step 1: Filter columns that end with '_20'
columns_to_keep = [col for col in filtered_df.columns if col.endswith('_20')]
columns_to_keep.append('cluster_labels')  # Make sure to keep the 'cluster_labels' column

filtered_20_df = filtered_df[columns_to_keep]

# Step 2: Rename the columns to remove the '_20' suffix
filtered_20_df.columns = [col[:-3] if col.endswith('_20') else col for col in filtered_20_df.columns]

# Step 3: Group by 'cluster_labels' and sum the values for each group
grouped_df = filtered_20_df.groupby('cluster_labels').sum()

# Step 4: Normalize the grouped values so that each bar equals 1
normalized_df = grouped_df.div(grouped_df.sum(axis=1), axis=0)

# Map the colors to the columns
colors = [cell_colors.get(col, 'grey') for col in normalized_df.columns]

# Step 5: Plot the stacked bar plot
plt.figure(figsize=(8, 8))
ax = normalized_df.plot(kind='bar', stacked=True, color=colors, figsize=(12, 8))

# Add labels and title
plt.xlabel('Cluster Labels')
plt.ylabel('Proportion')
plt.title('20um Neighborhood by Immune Cluster Labels')
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['left'].set_visible(False)
ax.spines['bottom'].set_visible(False)
plt.tick_params(axis='x', which='both', length=0)
plt.tick_params(axis='y', which='both', length=0)
# Adjust layout and move the legend below the plot
plt.legend(title='', bbox_to_anchor=(0.5, -0.22), loc='upper center', ncol=6, frameon=False)
plt.tight_layout()
plt.savefig('Immune Cluster 20um pie chart legend.png', dpi=450, bbox_inches='tight')
# Show the plot
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Assuming filtered_df is your dataframe
# Step 1: Filter columns that end with '_40'
columns_to_keep = [col for col in filtered_df.columns if col.endswith('_20')]
columns_to_keep.append('cluster_labels')  # Make sure to keep the 'cluster_labels' column

filtered_40_df = filtered_df[columns_to_keep]

# Step 2: Rename the columns to remove the '_40' suffix
filtered_40_df.columns = [col[:-3] if col.endswith('_20') else col for col in filtered_40_df.columns]

# Step 3: Group by 'cluster_labels' and sum the values for each group
grouped_df = filtered_40_df.groupby('cluster_labels').sum()

# Step 4: Normalize the grouped values so that each pie chart equals 1
normalized_df = grouped_df.div(grouped_df.sum(axis=1), axis=0)

# Map the colors to the columns
colors = [cell_colors.get(col, 'grey') for col in normalized_df.columns]

# Step 5: Plot a pie chart for each cluster label
for label in normalized_df.index:
    plt.figure(figsize=(8, 8))
    plt.pie(normalized_df.loc[label],  colors=colors, autopct=None) ##labels=normalized_df.columns,
    print(label)
    plt.title('')

    # Remove the frame around the plot
    plt.gca().spines['top'].set_visible(False)
    plt.gca().spines['right'].set_visible(False)
    plt.gca().spines['left'].set_visible(False)
    plt.gca().spines['bottom'].set_visible(False)

    # Save the figure
    plt.savefig(f'Immune_Cluster_20um_pie_chart_update_{label}.png', dpi=450, bbox_inches='tight')
    plt.show()

"""where are the resident immune cells"""

adata

adata_subset=adata[adata.obs['immune_subcluster_ME']!='outlier']

cluster_labels_all = adata_subset.obs["immune_subcluster_ME"].value_counts()

cluster_labels_all

import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.preprocessing import MinMaxScaler

# Assuming new_adata_subset is your AnnData object and it has the annotations and cluster labels
# Extract the relevant columns
annotations = adata_subset.obs["immune_cell_update"]
cluster_labels = adata_subset.obs["immune_subcluster_ME"]

# Create a contingency table (cross-tabulation)
contingency_table = pd.crosstab(cluster_labels, annotations)

# Assuming you have already loaded your contingency_table and cluster_labels_all as pandas DataFrames or Series

# Convert cluster_labels_all to a DataFrame to align indices for division
cluster_labels_all_df = cluster_labels_all.to_frame().rename(columns={'count': 'total_count'})

# Merge the contingency_table with cluster_labels_all to ensure correct alignment
merged_df = contingency_table.merge(cluster_labels_all_df, left_index=True, right_index=True)

# Normalize each row in contingency_table by the corresponding value in cluster_labels_all
normalized_contingency_table = merged_df.div(merged_df['total_count'], axis=0).drop(columns='total_count')


normalized_contingency_table

# Scale the data from 0 to 1 across the columns
scaler = MinMaxScaler()
scaled_table = pd.DataFrame(scaler.fit_transform(normalized_contingency_table),
                            index=normalized_contingency_table.index,
                            columns=normalized_contingency_table.columns)
desired_column_order = ['NK','Baso/Mast','Macro I', 'Macro II','Neutrophil','cDC', 'CD8+ I', 'Plasma', 'CD8+ II','mDC', 'pDC','CD4+', 'B',
          ]  # Replace with actual annotation labels
desired_index_order = ['Immune ME 1','Immune ME 6','Immune ME 2','Immune ME 5','Immune ME 4','Immune ME 3',]  # Replace with actual cluster labels
scaled_table_reindex = scaled_table.reindex(index=desired_index_order, columns=desired_column_order)
# Plot the heatmap
plt.figure(figsize=(6, 5))
sns.heatmap(scaled_table_reindex, annot=False, fmt=".2f", cmap="Blues",cbar_kws={'shrink': 0.1, 'orientation': 'horizontal', 'pad': 0.3})
plt.title('')
plt.tick_params(axis='x', which='both', length=0)
plt.tick_params(axis='y', which='both', length=0)
plt.xlabel('')
plt.ylabel('')
plt.savefig('Immune Zonation blue plot 2.png', dpi=450, bbox_inches='tight')
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler

# Sample data for demonstration
# normalized_contingency_table = pd.DataFrame(...)

# Scale the data from 0 to 1 across the columns
scaler = MinMaxScaler()
scaled_table = pd.DataFrame(scaler.fit_transform(normalized_contingency_table),
                            index=normalized_contingency_table.index,
                            columns=normalized_contingency_table.columns)

desired_column_order = [ 'NK','Baso/Mast', 'Macro I', 'Macro II',  'CD8+ I',  'B', 'CD4+',
                        'mDC', 'pDC','CD8+ II', 'Plasma', 'Neutrophil', 'cDC',]  # Replace with actual annotation labels
desired_index_order = ['Immune ME 1', 'Immune ME 2', 'Immune ME 3', 'Immune ME 4', 'Immune ME 5', 'Immune ME 6']  # Replace with actual cluster labels
scaled_table_reindex = scaled_table.reindex(index=desired_index_order, columns=desired_column_order)

# Transpose the table to switch rows and columns
scaled_table_reindex = scaled_table_reindex.T

# Plot the heatmap
plt.figure(figsize=(3, 10))
sns.heatmap(scaled_table_reindex, annot=False, fmt=".2f", cmap="Blues",
            cbar_kws={'shrink': 0.6, 'orientation': 'horizontal', 'pad': 0.2})
plt.title('')
plt.tick_params(axis='x', which='both', length=0)
plt.tick_params(axis='y', which='both', length=0)
plt.xlabel('')
plt.ylabel('')
plt.savefig('Immune_Zonation_blue_plot_2.png', dpi=450, bbox_inches='tight')
plt.show()



adata.obs['immune_subcluster_ME_20um'].value_counts()

subset=adata[adata.obs['immune_subcluster_ME_20um']!='outlier']

overlap={
    'immune': subset.obs['immune_subcluster_ME_20um'],
    'iPT': subset.obs['iPT_subcluster_ME_20um']
}
overlap_df = pd.DataFrame(overlap)

overlap_df['immune']=overlap_df['immune'].replace('Immune ME 1', 'Residential')
overlap_df['immune']=overlap_df['immune'].replace('Immune ME 2', 'iPT-Immune')
overlap_df['immune']=overlap_df['immune'].replace('Immune ME 3', 'B predom.')
overlap_df['immune']=overlap_df['immune'].replace('Immune ME 4', 'CD4+ predom.')
overlap_df['immune']=overlap_df['immune'].replace('Immune ME 5', 'iTAL-Immune')
overlap_df['immune']=overlap_df['immune'].replace('Immune ME 6', 'Fibro-Immune')
overlap_df

import pandas as pd
from matplotlib_venn import venn2, venn2_circles
import matplotlib.pyplot as plt

# Assuming overlap_df is your DataFrame with 'immune' and 'iTAL' columns

# Create sets of row indices for each cluster label in 'immune'
immune_clusters = overlap_df['immune'].unique()
immune_sets = {label: set(overlap_df.index[overlap_df['immune'] == label]) for label in immune_clusters}

# Create sets of row indices for each cluster label in 'iTAL'
iTAL_clusters = overlap_df['iTAL'].unique()
iTAL_sets = {label: set(overlap_df.index[overlap_df['iTAL'] == label]) for label in iTAL_clusters}

# Initialize the Venn diagram
plt.figure(figsize=(12, 12))

# Plot each combination of cluster labels
for i, immune_label in enumerate(immune_clusters):
    if immune_label == 'outlier':
        continue
    for j, iTAL_label in enumerate(iTAL_clusters):
        if iTAL_label == 'outlier':
            continue
        plt.subplot(len(immune_clusters), len(iTAL_clusters), i * len(iTAL_clusters) + j + 1)

        # Calculate intersection
        intersection_count = len(immune_sets[immune_label] & iTAL_sets[iTAL_label])

        # Plot Venn diagram with labels but no numbers
        venn = venn2([immune_sets[immune_label], iTAL_sets[iTAL_label]], set_labels=(immune_label, iTAL_label))

        # Add circles around the Venn diagram sets
        venn2_circles([immune_sets[immune_label], iTAL_sets[iTAL_label]])

        # Clear numerical values from the default labels
        for idx in ['10', '01', '11']:
            label = venn.get_label_by_id(idx)
            if label is not None:
                label.set_text('')

        # Add the intersection number above the circles
        if venn.get_label_by_id('11') is not None:
            venn.get_label_by_id('11').set_text('')
        plt.text(0.5, 1, f'Intersecting cells: {intersection_count}', horizontalalignment='center', verticalalignment='bottom', transform=plt.gca().transAxes, fontsize=12)

plt.tight_layout()
plt.savefig('overlap_immune_iTAL.png', dpi=450, bbox_inches='tight')
plt.show()

import pandas as pd
from matplotlib_venn import venn2, venn2_circles
import matplotlib.pyplot as plt

# Assuming overlap_df is your DataFrame with 'immune' and 'iTAL' columns

# Create sets of row indices for each cluster label in 'immune'
immune_clusters = overlap_df['immune'].unique()
immune_sets = {label: set(overlap_df.index[overlap_df['immune'] == label]) for label in immune_clusters}

# Create sets of row indices for each cluster label in 'iTAL'
iTAL_clusters = overlap_df['iPT'].unique()
iTAL_sets = {label: set(overlap_df.index[overlap_df['iPT'] == label]) for label in iTAL_clusters}

# Initialize the Venn diagram
plt.figure(figsize=(12, 12))

# Plot each combination of cluster labels
for i, immune_label in enumerate(immune_clusters):
    if immune_label == 'outlier':
        continue
    for j, iTAL_label in enumerate(iTAL_clusters):
        if iTAL_label == 'outlier':
            continue
        plt.subplot(len(immune_clusters), len(iTAL_clusters), i * len(iTAL_clusters) + j + 1)

        # Calculate intersection
        intersection_count = len(immune_sets[immune_label] & iTAL_sets[iTAL_label])

        # Plot Venn diagram with labels but no numbers
        venn = venn2([immune_sets[immune_label], iTAL_sets[iTAL_label]], set_labels=(immune_label, iTAL_label))

        # Add circles around the Venn diagram sets
        venn2_circles([immune_sets[immune_label], iTAL_sets[iTAL_label]])

        # Clear numerical values from the default labels
        for idx in ['10', '01', '11']:
            label = venn.get_label_by_id(idx)
            if label is not None:
                label.set_text('')

        # Add the intersection number above the circles
        if venn.get_label_by_id('11') is not None:
            venn.get_label_by_id('11').set_text('')
        plt.text(0.5, 1, f'Intersecting cells: {intersection_count}', horizontalalignment='center', verticalalignment='bottom', transform=plt.gca().transAxes, fontsize=12)

plt.tight_layout()
plt.savefig('overlap_immune_iPT.png', dpi=450, bbox_inches='tight')
plt.show()

import pandas as pd
from matplotlib_venn import venn2
import matplotlib.pyplot as plt

# Assuming overlap_df is your DataFrame with 'immune' and 'iTAL' columns

# Create sets of row indices for each cluster label in 'immune'
immune_clusters = overlap_df['immune'].unique()
immune_sets = {label: set(overlap_df.index[overlap_df['immune'] == label]) for label in immune_clusters}

# Create sets of row indices for each cluster label in 'iTAL'
iTAL_clusters = overlap_df['iTAL'].unique()
iTAL_sets = {label: set(overlap_df.index[overlap_df['iTAL'] == label]) for label in iTAL_clusters}

# Initialize the Venn diagram
plt.figure(figsize=(12, 12))

# Plot each combination of cluster labels
for i, immune_label in enumerate(immune_clusters):
    if immune_label == 'outlier':
        continue
    for j, iTAL_label in enumerate(iTAL_clusters):
        if iTAL_label == 'outlier':
            continue
        plt.subplot(len(immune_clusters), len(iTAL_clusters), i * len(iTAL_clusters) + j + 1)

        # Calculate intersection
        intersection_count = len(immune_sets[immune_label] & iTAL_sets[iTAL_label])

        # Plot Venn diagram with labels but no numbers
        venn = venn2([immune_sets[immune_label], iTAL_sets[iTAL_label]], set_labels=(immune_label, iTAL_label))

        # Clear numerical values from the default labels
        for idx in ['10', '01', '11']:
            label = venn.get_label_by_id(idx)
            if label is not None:
                label.set_text('')

        # Add only the intersection number if it exists
        intersection_label = venn.get_label_by_id('11')
        if intersection_label is not None:
            intersection_label.set_text(str(intersection_count))

plt.tight_layout()
plt.savefig('overlap_immune_iTAL.png', dpi=450, bbox_inches='tight')
plt.show()





sn_imputed_immune=sc.read_h5ad('/content/drive/MyDrive/Bernhard/Immune_Cell_Atlas/Cosmx_immune_imputed_from_SN_np.h5ad')

sn_imputed_immune.obs['immune_subcluster_ME']=adata.obs['immune_subcluster_ME'].copy()

print(sn_imputed_immune.obs['immune_subcluster_ME'])

print(adata_subset.obs['immune_subcluster_ME'])

sc.pl.umap(sn_imputed_immune, color = "annotations_after_scanvi_simple")

for annotation in sn_imputed_immune.obs['annotations_after_scanvi_simple'].unique():
  if annotation == 'Macro III':
    continue
  if annotation == 'Macro IV':
    continue
  if annotation == 'Cycling':
    continue
  if annotation == 'Baso/Mast':
    continue
  print(annotation)
  subset
  subset=sn_imputed_immune[sn_imputed_immune.obs['annotations_after_scanvi_simple']==annotation]
  sc.tl.rank_genes_groups(subset, groupby='immune_subcluster_ME', method='wilcoxon', pts = True)
  sc.pl.rank_genes_groups(subset, n_genes=25, sharey=False)
  de_results = subset.uns['rank_genes_groups']
  folder_name = '/content/drive/MyDrive/Bernhard/Cosmx/After_Cleaning/Immune_TLO/Immune_MEs'

  # Iterate through each group to save DEG lists
  for group in de_results['names'].dtype.names:
    gene_names = de_results['names'][group]
    gene_scores = de_results['scores'][group]
    gene_logfoldchanges = de_results['logfoldchanges'][group]
    gene_pvals = de_results['pvals'][group]
    gene_pvals_adj = de_results['pvals_adj'][group]

    # Create a DataFrame
    df = pd.DataFrame({
        'Gene': gene_names,
        'Score': gene_scores,
        'LogFoldChange': gene_logfoldchanges,
        'pValue': gene_pvals,
        'pValue_adj': gene_pvals_adj
    })
    print(df.head(55))
    # Define the filename
    filename = os.path.join(folder_name, f"{annotation}_{group}_DEG.csv")

    # Save the DataFrame to a CSV file
    df.to_csv(filename, index=False)

    print(f"Saved DEG list for group {annotation} {group} to {filename}")

import os
import pandas as pd

folder_name = '/content/drive/MyDrive/Bernhard/Cosmx/After_Cleaning/Immune_TLO/Immune_MEs'

# Create a dictionary to store dataframes
dataframes = {}

# List all files in the folder
for filename in os.listdir(folder_name):
    if filename.endswith('.csv'):
        # Create the dataframe name by stripping off the '.csv' extension and replacing spaces with underscores
        df_name = filename[:-4].replace(' ', '_')
        df_name=df_name.replace('+','_')
        # Read the CSV file into a dataframe
        df_path = os.path.join(folder_name, filename)
        dataframes[df_name] = pd.read_csv(df_path)
        print(f"Loaded dataframe: {df_name} with shape: {dataframes[df_name].shape}")

for df_name, df in dataframes.items():
    globals()[df_name] = df
    print(f"Created dataframe variable: {df_name} with shape: {df.shape}")

!pip --quiet install gseapy

import gseapy
from gseapy import barplot, dotplot

human = gseapy.get_library_name(organism='Human')

populations_to_test = [Plasma_Immune_ME_5_DEG]
very_small_value = 1e-310

for i in populations_to_test:
    i['pValue_adj'] = i['pValue_adj'].replace(0, very_small_value)
    i["names"] = i['Gene']
    i["pi_score"] = -1 * np.log10(i["pValue_adj"]) * i["LogFoldChange"] # pvalue
    i.dropna(inplace=True)

Plasma_Immune_ME_5_DEG

from gseapy import Msigdb

v_library='WikiPathway_2023_Human' ## 'WikiPathway_2023_Human' ###
gset = gseapy.parser.get_library(v_library, min_size=20)

gene_rank = Plasma_Immune_ME_5_DEG[['names','pi_score']]
gene_rank.sort_values(by=['pi_score'], inplace=True, ascending=False)
gene_rank = gene_rank.reset_index(drop=True)

res = gseapy.prerank(rnk=gene_rank, gene_sets=gset)

res.res2d.head(20)
df4=res.res2d.copy()

df4

names = gseapy.get_library_name()

 # show top 20 entries.
print(names)

v_library='c7.immunesigdb.v2023.2.Hs' ## 'WikiPathway_2023_Human' ###
gset = gseapy.parser.get_library(v_library, min_size=20)

import json
import gseapy
from gseapy import barplot, dotplot

# Path to the downloaded JSON file
json_file = '/content/c7.immunesigdb.v2023.2.Hs.json'

with open(json_file, 'r') as f:
    gset = json.load(f)

# Convert the gene sets to a dictionary if not already in that format
if isinstance(gset, list):
    gset = {entry['name']: entry['genes'] for entry in gset}

# Check the results
print(gset)



gset

import json
import gseapy
from gseapy import barplot, dotplot

# Path to the downloaded JSON file
json_file = '/content/REACTOME_IMMUNE_SYSTEM.v2023.2.Hs.json'

# Load the gene sets from the JSON file
with open(json_file, 'r') as f:
    gset = json.load(f)

# Reformat the gene sets to the required format
formatted_gset_2 = {}
for entry in gset:
    genes = gset[entry]['geneSymbols']
    formatted_gset_2[entry] = genes



json_file = '/content/c7.immunesigdb.v2023.2.Hs.json'

# Load the gene sets from the JSON file
with open(json_file, 'r') as f:
    gset = json.load(f)

# Reformat the gene sets to the required format
formatted_gset = {}
for entry in gset:
    genes = gset[entry]['geneSymbols']
    formatted_gset[entry] = genes

gene_rank = B_Immune_ME_1_DEG[['names','pi_score']]
gene_rank.sort_values(by=['pi_score'], inplace=True, ascending=False)
gene_rank = gene_rank.reset_index(drop=True)

res = gseapy.prerank(rnk=gene_rank, gene_sets=formatted_gset)

res.res2d.head(20)
df1=res.res2d.copy()
df1 = df1[df1['Term'].str.contains('BCELL', case=False)]

gene_rank = B_Immune_ME_2_DEG[['names','pi_score']]
gene_rank.sort_values(by=['pi_score'], inplace=True, ascending=False)
gene_rank = gene_rank.reset_index(drop=True)

res = gseapy.prerank(rnk=gene_rank, gene_sets=formatted_gset)

res.res2d.head(20)
df2=res.res2d.copy()
df2 = df2[df2['Term'].str.contains('BCELL', case=False)]

gene_rank = B_Immune_ME_3_DEG[['names','pi_score']]
gene_rank.sort_values(by=['pi_score'], inplace=True, ascending=False)
gene_rank = gene_rank.reset_index(drop=True)

res = gseapy.prerank(rnk=gene_rank, gene_sets=formatted_gset)

res.res2d.head(20)
df3=res.res2d.copy()
df3 = df3[df3['Term'].str.contains('BCELL', case=False)]

gene_rank = B_Immune_ME_4_DEG[['names','pi_score']]
gene_rank.sort_values(by=['pi_score'], inplace=True, ascending=False)
gene_rank = gene_rank.reset_index(drop=True)

res = gseapy.prerank(rnk=gene_rank, gene_sets=formatted_gset)

res.res2d.head(20)
df4=res.res2d.copy()
df4 = df4[df4['Term'].str.contains('BCELL', case=False)]

gene_rank = B_Immune_ME_5_DEG[['names','pi_score']]
gene_rank.sort_values(by=['pi_score'], inplace=True, ascending=False)
gene_rank = gene_rank.reset_index(drop=True)

res = gseapy.prerank(rnk=gene_rank, gene_sets=formatted_gset)

res.res2d.head(20)
df5=res.res2d.copy()
df5 = df5[df5['Term'].str.contains('BCELL', case=False)]

gene_rank = B_Immune_ME_6_DEG[['names','pi_score']]
gene_rank.sort_values(by=['pi_score'], inplace=True, ascending=False)
gene_rank = gene_rank.reset_index(drop=True)

res = gseapy.prerank(rnk=gene_rank, gene_sets=formatted_gset)

res.res2d.head(20)
df6=res.res2d.copy()
df6 = df6[df6['Term'].str.contains('BCELL', case=False)]

df1_simple=df1.set_index('Term')
df1_simple.loc[df1_simple['FDR q-val'] > 0.25, 'NES'] = 0
df1_simple=df1_simple.drop(['Name', 'ES', 'NOM p-val', 'FDR q-val','FWER p-val', 'Tag %', 'Gene %', 'Lead_genes'], axis=1)
df1_simple.rename(columns={'NES': 'Immune ME 1'}, inplace=True)

df2_simple=df2.set_index('Term')
df2_simple.loc[df2_simple['FDR q-val'] > 0.25, 'NES'] = 0
df2_simple=df2_simple.drop(['Name', 'ES', 'NOM p-val', 'FDR q-val','FWER p-val', 'Tag %', 'Gene %', 'Lead_genes'], axis=1)
df2_simple.rename(columns={'NES': 'Immune ME 2'}, inplace=True)

df3_simple=df3.set_index('Term')
df3_simple.loc[df3_simple['FDR q-val'] > 0.25, 'NES'] = 0
df3_simple=df3_simple.drop(['Name', 'ES', 'NOM p-val', 'FDR q-val','FWER p-val', 'Tag %', 'Gene %', 'Lead_genes'], axis=1)
df3_simple.rename(columns={'NES': 'Immune ME 3'}, inplace=True)

df4_simple=df4.set_index('Term')
df4_simple.loc[df4_simple['FDR q-val'] > 0.25, 'NES'] = 0
df4_simple=df4_simple.drop(['Name', 'ES', 'NOM p-val', 'FDR q-val','FWER p-val', 'Tag %', 'Gene %', 'Lead_genes'], axis=1)
df4_simple.rename(columns={'NES': 'Immune ME 4'}, inplace=True)

df5_simple=df5.set_index('Term')
df5_simple.loc[df5_simple['FDR q-val'] > 0.25, 'NES'] = 0
df5_simple=df5_simple.drop(['Name', 'ES', 'NOM p-val', 'FDR q-val','FWER p-val', 'Tag %', 'Gene %', 'Lead_genes'], axis=1)
df5_simple.rename(columns={'NES': 'Immune ME 5'}, inplace=True)

df6_simple=df6.set_index('Term')
df6_simple.loc[df6_simple['FDR q-val'] > 0.25, 'NES'] = 0
df6_simple=df6_simple.drop(['Name', 'ES', 'NOM p-val', 'FDR q-val','FWER p-val', 'Tag %', 'Gene %', 'Lead_genes'], axis=1)
df6_simple.rename(columns={'NES': 'Immune ME 6'}, inplace=True)

merged_df = pd.concat([df1_simple,df2_simple], axis=1)
merged_df = pd.concat([merged_df, df3_simple], axis=1)
merged_df = pd.concat([merged_df,df4_simple], axis=1)
merged_df = pd.concat([merged_df, df5_simple], axis=1)
merged_df = pd.concat([merged_df,df6_simple], axis=1)
merged_df

merged_df=merged_df.astype(float)

plt.figure(figsize=(90, 60))
sns.heatmap(merged_df, annot=False, cmap='coolwarm')

# Add labels and title
plt.title('Heatmap of Gene Set Enrichment')
plt.xlabel('Niche')
plt.ylabel('Term')

# Adjust layout
plt.tight_layout()

# Show the plot
plt.show()

merged_df.shape

merged_df['sum']=merged_df.sum(axis=1)
merged_df=merged_df[merged_df['sum']!=0]
merged_df.shape

merged_df=merged_df.drop('sum', axis=1)

plt.figure(figsize=(90, 60))
sns.heatmap(merged_df, annot=False, cmap='coolwarm')

# Add labels and title
plt.title('Heatmap of Gene Set Enrichment')
plt.xlabel('Niche')
plt.ylabel('Term')

# Adjust layout
plt.tight_layout()

# Show the plot
plt.show()

merged_df
merged_df_2 = merged_df[merged_df.index.str.endswith('_UP')]

# Display the filtered DataFrame
print(merged_df_2)

merged_df_2

merged_df

def filter_rows(row):
    positive_values = row[row > 0]
    if len(positive_values) == 1:
        return True
    return False

filtered_df = merged_df_2[merged_df_2.apply(filter_rows, axis=1)]
filtered_df.shape

column_order = ['Immune ME 1','Immune ME 2','Immune ME 3','Immune ME 4','Immune ME 5','Immune ME 6',]

# Identify the column with the highest value for each row
filtered_df['max_column'] = filtered_df.idxmax(axis=1)

# Create a mapping for the desired order
column_mapping = {col: i for i, col in enumerate(column_order)}

# Map the max_column to the desired order
filtered_df['max_column_order'] = filtered_df['max_column'].map(column_mapping)

# Sort the DataFrame based on the mapped order
sorted_df = filtered_df.sort_values(by='max_column_order').drop(columns=['max_column', 'max_column_order'])

# Reorder the columns according to the desired order
sorted_df = sorted_df[column_order]

# Create the heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(sorted_df, annot=False, cmap='coolwarm')

# Add labels and title
plt.title('Heatmap of Sorted Gene Set Enrichment')
plt.xlabel('Niche')
plt.ylabel('Term')

# Adjust layout
plt.tight_layout()

# Show the plot
plt.show()

plt.figure(figsize=(15, 30))
sns.heatmap(sorted_df, annot=False, cmap='coolwarm')

# Add labels and title
plt.title('Heatmap of Sorted Gene Set Enrichment')
plt.xlabel('Niche')
plt.ylabel('Term')

# Adjust layout
plt.tight_layout()

# Show the plot
plt.show()





"""lets try with the science subsets from the blueprint of tumor infiltrating b cells"""

b_cell_subset_genes=pd.read_csv('/content/b_cell_subsets.csv')

b_cell_subset_genes.head(20)

b_cell_subset_genes_2=b_cell_subset_genes[b_cell_subset_genes['avg_log2FC']>0.5]

custom_gene_set = b_cell_subset_genes_2.groupby('cluster_name')['geneSymbol'].apply(list).to_dict()

# Print the custom gene set to verify
print(custom_gene_set)

sn_imputed_immune_b_cells=sn_imputed_immune[sn_imputed_immune.obs['annotations_after_scanvi_simple']=='B']
sn_imputed_immune_b_cells

for gene_set_name, genes in custom_gene_set.items():
    # Ensure that the genes are in uppercase
    genes = [gene.upper() for gene in genes]

    # Score the genes for the given gene set
    sc.tl.score_genes(sn_imputed_immune_b_cells, gene_list=genes, score_name=gene_set_name)

sn_imputed_immune_b_cells

scores_df = sn_imputed_immune_b_cells.obs[list(custom_gene_set.keys()) + ['immune_subcluster_ME']]
scores_df

scores_df=scores_df[scores_df['immune_subcluster_ME']!='outlier']

grouped_scores_df = scores_df.groupby('immune_subcluster_ME').mean()
grouped_scores_df=grouped_scores_df.drop('outlier', axis=0)
grouped_scores_df

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaled_data = scaler.fit_transform(grouped_scores_df)
scaled_df = pd.DataFrame(scaled_data, index=grouped_scores_df.index, columns=grouped_scores_df.columns)

# Plot the heatmap using seaborn
plt.figure(figsize=(12, 8))
sns.heatmap(grouped_scores_df, annot=True, cmap='viridis')
plt.title('Scaled Mean Immune Scores by Immune Microenvironment')
plt.xlabel('Gene Sets')
plt.ylabel('Immune Microenvironment')
plt.show()

# Plot the heatmap using seaborn
plt.figure(figsize=(10, 6))
sns.heatmap(scaled_df, annot=True, cmap='viridis')
plt.title('B Cell Subset Scores by Immune Microenvironment')
plt.xlabel('')
plt.ylabel('')
plt.tick_params(axis='both', which='both', length=0)
plt.savefig('B Cell Subset Scores all.png', dpi=450, bbox_inches='tight')
plt.show()



# Plot the heatmap using seaborn
plt.figure(figsize=(4, 6))
sns.heatmap(scaled_df.T, annot=False, cmap='viridis')
plt.title('Scaled Mean Immune Scores by Immune Microenvironment')
plt.xlabel('')
plt.ylabel('')
plt.show()

scaled_df_subset=scaled_df['B10.ENO1+PreGC']

scaled_df_subset=pd.DataFrame(scaled_df_subset, index=scaled_df.index)

scaled_df_subset

scaled_df_subset

scaled_df_subset.index = scaled_df_subset.index.str.replace('Immune ', '')

# Verify the changes
print(scaled_df_subset)

plt.figure(figsize=(7, 0.5))
sns.heatmap(scaled_df_subset.T, annot=True, cmap='viridis')
plt.title('')
plt.xlabel('')
plt.ylabel('')
plt.tick_params(axis='both', which='both', length=0)
plt.savefig('B Cell Subset Scores only PreGC.png', dpi=450, bbox_inches='tight')
plt.show()

scaled_df

scores_df

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaled_data = scaler.fit_transform(scores_df.drop('immune_subcluster_ME', axis=1))
scaled_df_2 = pd.DataFrame(scaled_data, index=scores_df.index, columns=scores_df.drop('immune_subcluster_ME', axis=1).columns)

scaled_df_2['immune_subcluster_ME']=scores_df['immune_subcluster_ME'].copy()

adata_subset_b=adata[adata.obs['immune_cell_update']=='B']
adata_subset_b=adata_subset_b[adata_subset_b.obs['immune_subcluster_ME']!='outlier']
adata_subset_b.X=adata_subset_b.layers['counts'].copy()
sc.pp.log1p(adata_subset_b)

import pandas as pd
from scipy.sparse import issparse
# Assuming 'adata' is your AnnData object
markers = ["ENO1"]

# Ensure markers list only includes valid gene names
markers = [gene for gene in markers if gene in adata_subset_b.var_names]

# Subset the .X matrix for the markers and convert to a DataFrame
gene_expression_df_unimputed = pd.DataFrame(
    adata_subset_b[:, markers].X.toarray() if issparse(adata_subset_b.X) else adata_subset_b[:, markers].X,
    index=adata_subset_b.obs_names,
    columns=markers
)

gene_expression_df_unimputed['immune_subcluster_ME'] = adata_subset_b.obs['immune_subcluster_ME'].values
mean_expression_per_cluster_unimputed = gene_expression_df_unimputed.groupby('immune_subcluster_ME').mean()

from sklearn.preprocessing import MinMaxScaler

# Create a MinMaxScaler object
scaler = MinMaxScaler()

# Scale each column individually
gene_expression_scaled_unimputed = scaler.fit_transform(mean_expression_per_cluster_unimputed)

# Convert the scaled array back to a DataFrame
gene_expression_scaled_df_unimputed = pd.DataFrame(gene_expression_scaled_unimputed, index=mean_expression_per_cluster_unimputed.index, columns=mean_expression_per_cluster_unimputed.columns)

# Display the first few rows of the scaled dataframe
#print(gene_expression_scaled_df_unimputed)

import matplotlib.pyplot as plt
import seaborn as sns

# Assuming 'gene_expression_scaled_df_unimputed' is your DataFrame and it's correctly formatted
# The '.T' is transposing the DataFrame, which is typical in heatmaps for better visualization of genes on one axis

plt.figure(figsize=(8, 1))  # Adjust the figure size as needed
heatmap = sns.heatmap(gene_expression_scaled_df_unimputed.T, cmap='plasma', annot=True, vmax=1, cbar_kws={"shrink": .3})

# Adjust the size of the colorbar
heatmap.collections[0].colorbar.ax.set_ylabel('')
heatmap.collections[0].colorbar.ax.set_xlabel('')
# Removing the tick marks as requested (optional)
plt.tick_params(axis='both', which='both', length=0)  # Ensures no tick marks on both x and y axes

# Save the figure
#plt.savefig('heatmap_iTAL_ME.png', dpi=450, bbox_inches='tight')

# Show the plot
plt.show()



markers = [ "ENO1", "COTL1", "RAC2", "CD79A"]

sc.pl.dotplot(adata_subset_b, markers, groupby='immune_subcluster_ME', cmap='Blues', log = False)

adata_subset_b.obs['immune_subcluster_ME'].value_counts()



adata

custom_gene_set = b_cell_subset_genes.groupby('cluster_name')['geneSymbol'].apply(list).to_dict()

# Print the custom gene set to verify
print(custom_gene_set)

# Sort and reset index
gene_rank = B_Immune_ME_4_DEG[['names', 'pi_score']]
gene_rank.sort_values(by=['pi_score'], inplace=True, ascending=False)
gene_rank = gene_rank.reset_index(drop=True)

# Prepare the DataFrame for prerank analysis
gene_rank_rnk = gene_rank.set_index('names')['pi_score']

# Run prerank analysis with your custom gene set
res = gseapy.prerank(rnk=gene_rank_rnk, gene_sets=custom_gene_set, min_size=1, max_size=5000)

# Display the top results
print(res.res2d.head(20))
df4=res.res2d.copy()

df4

# Sort and reset index
gene_rank = B_Immune_ME_2_DEG[['names', 'pi_score']]
gene_rank.sort_values(by=['pi_score'], inplace=True, ascending=False)
gene_rank = gene_rank.reset_index(drop=True)

# Prepare the DataFrame for prerank analysis
gene_rank_rnk = gene_rank.set_index('names')['pi_score']

# Run prerank analysis with your custom gene set
res = gseapy.prerank(rnk=gene_rank_rnk, gene_sets=custom_gene_set, min_size=1, max_size=5000)

# Display the top results
print(res.res2d.head(20))
df2=res.res2d.copy()

df2

adata

data={'ME':adata.obs['immune_subcluster_ME'],
    'region':adata.obs['cluster_labels_annotated_regions'],
    'type':adata.obs['type'],
      'annotation':adata.obs['immune_cell_update']}

df=pd.DataFrame(data)

df['type']=df['type'].replace('Pediatric','Healthy')

df=df[df['ME']=='Immune ME 1']
df=df.drop('ME', axis=1)
df=df[df['type']=='Healthy']
df=df.drop('type', axis=1)
df=df[df['region']!='outlier']
df=df[df['annotation']!='Macro III']
df=df[df['annotation']!='Macro IV']
df=df[df['annotation']!='cycling Lymphocytes']
df

grouped_df = df.groupby(['region', 'annotation']).size().reset_index(name='count')

# Display the grouped DataFrame
print(grouped_df)

grouped_df=grouped_df[grouped_df['region']!='outlier']
grouped_df=grouped_df[grouped_df['annotation']!='Macro III']
grouped_df=grouped_df[grouped_df['annotation']!='Macro IV']
grouped_df=grouped_df[grouped_df['annotation']!='cycling Lymphocytes']
grouped_df

pivot_df = grouped_df.pivot(index='annotation', columns='region', values='count')

# Display the transposed DataFrame
print(pivot_df)

total_counts

total_counts=pd.DataFrame(data)
total_counts

total_counts=total_counts.drop('annotation', axis=1)
total_counts=total_counts[total_counts['type']=='Healthy']
total_counts=total_counts[total_counts['region']!='outlier']
total_counts

total_counts=total_counts.drop(['ME','type'], axis=1)

grouped_total_counts = total_counts.groupby(['region']).size().reset_index(name='count')
grouped_total_counts=grouped_total_counts[grouped_total_counts['region']!='outlier']
grouped_total_counts

pivot_df

pivot_df['Cortex']=pivot_df['Cortex']/235746
pivot_df['Medulla']=pivot_df['Medulla']/102807
pivot_df

pivot_df['combined']=pivot_df['Cortex']/pivot_df['Medulla']
pivot_df

pivot_df_subset=pivot_df.drop(['Cortex', 'Medulla'], axis=1)

pivot_df_subset=pivot_df_subset.drop(['mDC', 'pDC'], axis=0)

plt.figure(figsize=(0.5, 8))  # Adjust the figure size as needed
pivot_df_subset = pivot_df_subset.round(1)
heatmap = sns.heatmap(pivot_df_subset, cmap='magma', annot=True, cbar_kws={"shrink": 2,  "orientation": "horizontal"}, vmax=0.5, vmin=1.5)
heatmap.set_xlabel('')
heatmap.set_ylabel('')
colorbar = heatmap.collections[0].colorbar
colorbar.set_ticks([0.5, 1.5])
colorbar.set_ticklabels(['Medulla', 'Cortex'])
# Removing the tick marks as requested (optional)
plt.tick_params(axis='both', which='both', length=0)  # Ensures no tick marks on both x and y axes
plt.tick_params(axis='y', labelright=True, labelleft=False, rotation = 0)

# Save the figure
plt.savefig('cortex medulla immune me1 right label vol 2.png', dpi=450, bbox_inches='tight')

# Show the plot
plt.show()

adata_subset=adata[adata.obs['immune_subcluster_ME']!='outlier']

print(adata_subset.obs['immune_subcluster_ME'].unique)

palette={
    'Immune ME 1': '#F07E20',
    'Immune ME 2': '#1E78B5',
    'Immune ME 3': '#2AA137',
    'Immune ME 4': '#D52528',
    'Immune ME 5': '#D279AF',
    'Immune ME 6': '#8C564C',
    'outlier':'#A8A8A7'
}

sc.pl.umap(adata, color = 'immune_subcluster_ME', palette=palette)

import matplotlib.pyplot as plt
import seaborn as sns

# Assuming new_adata_subset is your AnnData object
# Extract the relevant columns
samples = adata_subset.obs['sample']
cluster_labels = adata_subset.obs['immune_subcluster_ME']

# Create a DataFrame from the relevant columns
data = pd.DataFrame({'sample': samples, 'immune_subcluster_ME': cluster_labels})

# Group by 'sample' and 'cluster_labels_annotated' and count the occurrences
grouped_data = data.groupby(['sample', 'immune_subcluster_ME']).size().unstack(fill_value=0)
desired_order = [
    "Pediatric1", "HK2753", "HK3039", "HK3106", "HK3531", "HK3531_2",
    "HK3063", "HK3542", "HK2874", "HK2695", "HK3035", "HK3035_2",
     "HK2841", "HK2873","HK2844", "HK2844_2"
]

grouped_data=grouped_data.reindex(desired_order)
sample_totals = data['sample'].value_counts()
sample_totals=sample_totals.reindex(desired_order)
normalized_count_df = grouped_data.div(sample_totals, axis='index')
ax = normalized_count_df.plot(kind='bar', stacked=True, figsize=(8, 8), colormap='tab10')

# Set plot labels and title
plt.xlabel('')
plt.ylabel('Relative Amount')
plt.title('Sample Niche Composition')
plt.legend(title='Niche Labels', bbox_to_anchor=(1.05, 1), loc='upper left', frameon=False)
plt.tick_params(axis='x', which='both', length=0)
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
plt.tight_layout()
plt.savefig('immune me relative niche amount.png', dpi=450, bbox_inches='tight')
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd


# Assuming new_adata_subset is your AnnData object
# Extract the relevant columns
samples = adata_subset.obs['sample']
cluster_labels = adata_subset.obs['immune_subcluster_ME']

# Create a DataFrame from the relevant columns
data = pd.DataFrame({'sample': samples, 'immune_subcluster_ME': cluster_labels})

# Group by 'sample' and 'immune_subcluster_ME' and count the occurrences
grouped_data = data.groupby(['sample', 'immune_subcluster_ME']).size().unstack(fill_value=0)
desired_order = [
    "Pediatric1", "HK2753", "HK3039", "HK3106", "HK3531", "HK3531_2",
    "HK3063", "HK3542", "HK2874", "HK2695", "HK3035", "HK3035_2",
     "HK2841", "HK2873","HK2844", "HK2844_2"
]

grouped_data = grouped_data.reindex(desired_order)
sample_totals = data['sample'].value_counts()
sample_totals = sample_totals.reindex(desired_order)
normalized_count_df = grouped_data.div(sample_totals, axis='index')


# Get the colors in the order of the columns
colors = [palette[col] for col in normalized_count_df.columns]
normalized_count_df.columns = normalized_count_df.columns.str.replace('Immune ', '')
ax = normalized_count_df.plot(kind='bar', stacked=True, figsize=(6, 8), color=colors)

# Set plot labels and title
plt.xlabel('')
plt.ylabel('Relative Amount')
plt.title('')
#plt.legend(title='', bbox_to_anchor=(1.05, 1), loc='upper left', frameon=False)
plt.legend(title='', bbox_to_anchor=(0.5, 1), loc='lower center', ncol=6, frameon=False)

plt.tick_params(axis='x', which='both', length=0)
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
plt.tight_layout()
plt.savefig('immune_me_relative_niche_amount.png', dpi=450, bbox_inches='tight')
plt.show()

normalized_count_df







adata_all_subset=adata_all[adata_all.obs['immune_subcluster_ME']!='outlier']
for annotation in adata_all_subset.obs['immune_cell_update'].unique():
  print(annotation)
  subset=adata_all_subset[adata_all_subset.obs['immune_cell_update']==annotation]
  subset.X = subset.layers["counts"].copy()
  sc.pp.normalize_total(subset, inplace=True)
  sc.pp.log1p(subset)
  sc.tl.rank_genes_groups(subset, groupby='immune_subcluster_ME', method='wilcoxon', pts = True)
  sc.pl.rank_genes_groups(subset, n_genes=25, sharey=False)

from scipy.sparse import csr_matrix

all_dfs = []

for i in adata.obs["sample"].unique():
    adata_sample = adata[adata.obs["sample"] == i]
    connectivity_matrix = csr_matrix(adata_sample.obsp["20_micron_connectivities"])
    # Create a temporary DataFrame for the current AnnData object
    temp_df = pd.DataFrame(index=adata_sample.obs.index)

    # Extract neighbor cell IDs for each cell
    neighbor_cell_ids = []
    for cell_index in range(connectivity_matrix.shape[0]):
        # Extract the indices of non-zero elements (neighbor indices) in the row
        neighbor_indices = connectivity_matrix[cell_index, :].nonzero()[1]

        neighbor_ids = adata_sample.obs.index[neighbor_indices].tolist()
        neighbor_cell_ids.append(neighbor_ids)

    temp_df["neighbor_ids"] = neighbor_cell_ids

    # Append the temporary DataFrame to the list
    all_dfs.append(temp_df)

# Concatenate the DataFrames from each AnnData object
df_neighbor_ids = pd.concat(all_dfs, axis=0)

# Optionally, sort the index if needed
df_neighbor_ids.sort_index(inplace=True)

# Display the DataFrame
print(df_neighbor_ids)

df_neighbor_ids['cluster_labels']=adata.obs['immune_subcluster_ME']

subset_df=df_neighbor_ids[df_neighbor_ids['cluster_labels']!='outlier']
subset_df

# DataFrame for the index and cluster_label
index_cluster_df = subset_df.reset_index().rename(columns={'index': 'cell_id'})[['cell_id', 'cluster_labels']]

# DataFrame for the neighbor_ids and cluster_label
neighbors_cluster_df = subset_df.reset_index(drop=True)[['neighbor_ids', 'cluster_labels']]

print(index_cluster_df.head())  # Preview the DataFrame with cell_id and cluster_label
print(neighbors_cluster_df.head())  # Preview the DataFrame with neighbor_ids and cluster_label

# Explode the 'neighbor_ids' column to have each neighbor_id in its own row
exploded_neighbors_cluster_df = neighbors_cluster_df.explode('neighbor_ids')

# Drop duplicates in the 'neighbor_ids' column
exploded_neighbors_cluster_df = exploded_neighbors_cluster_df.drop_duplicates(subset='neighbor_ids')

print(exploded_neighbors_cluster_df)  # Preview the exploded and deduplicated DataFrame

# Rename 'neighbor_ids' column to 'cell_id' in exploded_neighbors_cluster_df for consistency
exploded_neighbors_cluster_df = exploded_neighbors_cluster_df.rename(columns={'neighbor_ids': 'cell_id'})

# Concatenate the DataFrames vertically
combined_df = pd.concat([index_cluster_df, exploded_neighbors_cluster_df], ignore_index=True)

print(combined_df)  # Preview the combined DataFrame

combined_df = combined_df.drop_duplicates(subset=['cell_id'])
combined_df

cluster_label_dict = combined_df.set_index('cell_id')['cluster_labels'].to_dict()
adata.obs['immune_subcluster_ME_20um'] = adata.obs_names.map(cluster_label_dict)

adata.obs['immune_subcluster_ME_20um']=adata.obs['immune_subcluster_ME_20um'].astype('category')
adata.obs['immune_subcluster_ME_20um'] = adata.obs['immune_subcluster_ME_20um'].cat.add_categories(['outlier'])
adata.obs["immune_subcluster_ME_20um"]=adata.obs["immune_subcluster_ME_20um"].fillna('outlier')

print(adata.obs['immune_subcluster_ME_20um'].value_counts())

adata

adata.write('/content/drive/MyDrive/Bernhard/Cosmx/After_Cleaning/all_Cosmx_cleaned_neighbored.h5ad')

import gc
gc.collect()

adata_all.obs['immune_subcluster_ME_20um']=adata.obs['immune_subcluster_ME_20um'].copy()

subset=adata_all[adata_all.obs['immune_subcluster_ME_20um']!='outlier']
subset.X = subset.layers["counts"].copy()
sc.pp.normalize_total(subset, inplace=True)
sc.pp.log1p(subset)
sc.tl.rank_genes_groups(subset, groupby='immune_subcluster_ME_20um', method='wilcoxon', pts = True)
sc.pl.rank_genes_groups(subset, n_genes=25, sharey=False)

de_results = subset.uns['rank_genes_groups']
for group in de_results['names'].dtype.names:
        if group == 'outlier':
          continue
        print(group)
        gene_names = de_results['names'][group]
        gene_scores = de_results['scores'][group]
        gene_logfoldchanges = de_results['logfoldchanges'][group]
        gene_pvals = de_results['pvals'][group]
        gene_pvals_adj = de_results['pvals_adj'][group]

        # Create a DataFrame
        df = pd.DataFrame({
            'Gene': gene_names,
            'Score': gene_scores,
            'LogFoldChange': gene_logfoldchanges,
            'pValue': gene_pvals,
            'pValue_adj': gene_pvals_adj
        })
        #df=df[df['LogFoldChange']>0.9]
        print(df.head(55))
        #print(f'{group}_DEGs.csv')
        df.to_csv(f'/content/drive/MyDrive/Bernhard/Cosmx/After_Cleaning/Immune_TLO/Immune_MEs/spatial_signature/immune_ME_alone_{group}_DEGs.csv')

adata_all.X = adata_all.layers["counts"]
sc.pp.log1p(adata_all)
sc.tl.rank_genes_groups(adata_all, groupby='immune_subcluster_ME_20um',method='wilcoxon', pts = True)
sc.pl.rank_genes_groups(adata_all, n_genes=25, sharey=False)

de_results = adata_all.uns['rank_genes_groups']
for group in de_results['names'].dtype.names:
        if group == 'outlier':
          continue
        print(group)
        gene_names = de_results['names'][group]
        gene_scores = de_results['scores'][group]
        gene_logfoldchanges = de_results['logfoldchanges'][group]
        gene_pvals = de_results['pvals'][group]
        gene_pvals_adj = de_results['pvals_adj'][group]

        # Create a DataFrame
        df = pd.DataFrame({
            'Gene': gene_names,
            'Score': gene_scores,
            'LogFoldChange': gene_logfoldchanges,
            'pValue': gene_pvals,
            'pValue_adj': gene_pvals_adj
        })
        #df=df[df['LogFoldChange']>0.9]
        print(df.head(55))
        #print(f'{group}_DEGs.csv')
        df.to_csv(f'/content/drive/MyDrive/Bernhard/Cosmx/After_Cleaning/Immune_TLO/Immune_MEs/spatial_signature/immune_ME_all_{group}_DE.csv')

immune1_all=pd.read_csv('/content/drive/MyDrive/Bernhard/Cosmx/After_Cleaning/Immune_TLO/Immune_MEs/spatial_signature/immune_ME_all_Immune ME 1_DE.csv')
immune2_all=pd.read_csv('/content/drive/MyDrive/Bernhard/Cosmx/After_Cleaning/Immune_TLO/Immune_MEs/spatial_signature/immune_ME_all_Immune ME 2_DE.csv')
immune3_all=pd.read_csv('/content/drive/MyDrive/Bernhard/Cosmx/After_Cleaning/Immune_TLO/Immune_MEs/spatial_signature/immune_ME_all_Immune ME 3_DE.csv')
immune4_all=pd.read_csv('/content/drive/MyDrive/Bernhard/Cosmx/After_Cleaning/Immune_TLO/Immune_MEs/spatial_signature/immune_ME_all_Immune ME 4_DE.csv')
immune5_all=pd.read_csv('/content/drive/MyDrive/Bernhard/Cosmx/After_Cleaning/Immune_TLO/Immune_MEs/spatial_signature/immune_ME_all_Immune ME 5_DE.csv')
immune6_all=pd.read_csv('/content/drive/MyDrive/Bernhard/Cosmx/After_Cleaning/Immune_TLO/Immune_MEs/spatial_signature/immune_ME_all_Immune ME 6_DE.csv')

immune1_alone=pd.read_csv('/content/drive/MyDrive/Bernhard/Cosmx/After_Cleaning/Immune_TLO/Immune_MEs/spatial_signature/immune_ME_alone_Immune ME 1_DEGs.csv')
immune2_alone=pd.read_csv('/content/drive/MyDrive/Bernhard/Cosmx/After_Cleaning/Immune_TLO/Immune_MEs/spatial_signature/immune_ME_alone_Immune ME 2_DEGs.csv')
immune3_alone=pd.read_csv('/content/drive/MyDrive/Bernhard/Cosmx/After_Cleaning/Immune_TLO/Immune_MEs/spatial_signature/immune_ME_alone_Immune ME 3_DEGs.csv')
immune4_alone=pd.read_csv('/content/drive/MyDrive/Bernhard/Cosmx/After_Cleaning/Immune_TLO/Immune_MEs/spatial_signature/immune_ME_alone_Immune ME 4_DEGs.csv')
immune5_alone=pd.read_csv('/content/drive/MyDrive/Bernhard/Cosmx/After_Cleaning/Immune_TLO/Immune_MEs/spatial_signature/immune_ME_alone_Immune ME 5_DEGs.csv')
immune6_alone=pd.read_csv('/content/drive/MyDrive/Bernhard/Cosmx/After_Cleaning/Immune_TLO/Immune_MEs/spatial_signature/immune_ME_alone_Immune ME 6_DEGs.csv')

immune1_all=immune1_all[immune1_all['pValue_adj']<0.01]
immune1_all=immune1_all[immune1_all['LogFoldChange']>1]
immune2_all=immune2_all[immune2_all['pValue_adj']<0.01]
immune2_all=immune2_all[immune2_all['LogFoldChange']>1]
immune3_all=immune3_all[immune3_all['pValue_adj']<0.01]
immune3_all=immune3_all[immune3_all['LogFoldChange']>1]
immune4_all=immune4_all[immune4_all['pValue_adj']<0.01]
immune4_all=immune4_all[immune4_all['LogFoldChange']>1]
immune5_all=immune5_all[immune5_all['pValue_adj']<0.01]
immune5_all=immune5_all[immune5_all['LogFoldChange']>1]
immune6_all=immune6_all[immune6_all['pValue_adj']<0.01]
immune6_all=immune6_all[immune6_all['LogFoldChange']>1]

immune1_alone=immune1_alone[immune1_alone['pValue_adj']<0.01]
immune1_alone=immune1_alone[immune1_alone['LogFoldChange']>2]
immune2_alone=immune2_alone[immune2_alone['pValue_adj']<0.01]
immune2_alone=immune2_alone[immune2_alone['LogFoldChange']>2]
immune3_alone=immune3_alone[immune3_alone['pValue_adj']<0.01]
immune3_alone=immune3_alone[immune3_alone['LogFoldChange']>2]
immune4_alone=immune4_alone[immune4_alone['pValue_adj']<0.01]
immune4_alone=immune4_alone[immune4_alone['LogFoldChange']>2]
immune5_alone=immune5_alone[immune5_alone['pValue_adj']<0.01]
immune5_alone=immune5_alone[immune5_alone['LogFoldChange']>2]
immune6_alone=immune6_alone[immune6_alone['pValue_adj']<0.01]
immune6_alone=immune6_alone[immune6_alone['LogFoldChange']>2]

immune1_genelist=immune1_all['Gene'].to_list()
immune2_genelist=immune2_all['Gene'].to_list()
immune3_genelist=immune3_all['Gene'].to_list()
immune4_genelist=immune4_all['Gene'].to_list()
immune5_genelist=immune5_all['Gene'].to_list()
immune6_genelist=immune6_all['Gene'].to_list()

not_in_immune1=immune2_all['Gene'].to_list()+immune3_all['Gene'].to_list()+immune4_all['Gene'].to_list()+immune5_all['Gene'].to_list()+immune6_all['Gene'].to_list()
not_in_immune2=immune1_all['Gene'].to_list()+immune3_all['Gene'].to_list()+immune4_all['Gene'].to_list()+immune5_all['Gene'].to_list()+immune6_all['Gene'].to_list()
not_in_immune3=immune1_all['Gene'].to_list()+immune2_all['Gene'].to_list()+immune4_all['Gene'].to_list()+immune5_all['Gene'].to_list()+immune6_all['Gene'].to_list()
not_in_immune4=immune1_all['Gene'].to_list()+immune2_all['Gene'].to_list()+immune3_all['Gene'].to_list()+immune5_all['Gene'].to_list()+immune6_all['Gene'].to_list()
not_in_immune5=immune1_all['Gene'].to_list()+immune2_all['Gene'].to_list()+immune3_all['Gene'].to_list()+immune4_all['Gene'].to_list()+immune6_all['Gene'].to_list()
not_in_immune6=immune1_all['Gene'].to_list()+immune2_all['Gene'].to_list()+immune3_all['Gene'].to_list()+immune4_all['Gene'].to_list()+immune5_all['Gene'].to_list()

unique_immune1 = [item for item in immune1_genelist if item not in not_in_immune1]
unique_immune2 = [item for item in immune2_genelist if item not in not_in_immune2]
unique_immune3 = [item for item in immune3_genelist if item not in not_in_immune3]
unique_immune4 = [item for item in immune4_genelist if item not in not_in_immune4]
unique_immune5 = [item for item in immune5_genelist if item not in not_in_immune5]
unique_immune6 = [item for item in immune6_genelist if item not in not_in_immune6]

unique_immune1

unique_immune2

unique_immune3

unique_immune4

unique_immune5

unique_immune6

unique_immune1=unique_immune1+immune1_alone['Gene'].to_list()
unique_immune2=unique_immune2+immune2_alone['Gene'].to_list()
unique_immune3=unique_immune3+immune3_alone['Gene'].to_list()
unique_immune4=unique_immune4+immune4_alone['Gene'].to_list()
unique_immune5=unique_immune5+immune5_alone['Gene'].to_list()
unique_immune6=unique_immune6+immune6_alone['Gene'].to_list()

unique_immune1

unique_immune2

unique_immune3

len(unique_immune4)

unique_immune4_set = set(unique_immune4)
unique_immune6_set = set(unique_immune6)

# Calculate the intersection of the two sets
intersection_set = unique_immune4_set.intersection(unique_immune6_set)

# Print the length of the intersection set
print(len(intersection_set))

intersection_set

unique_immune5

len(unique_immune6)

immune_me=adata[adata.obs['immune_subcluster_ME_20um']!='outlier']

overlap={
    'iPT': immune_me.obs['iPT_subcluster_ME_20um'],
    'iTAL': immune_me.obs['iTAL_subcluster_ME_20um'],
    'immune':immune_me.obs['immune_subcluster_ME_20um']

}
overlap_df = pd.DataFrame(overlap)

import pandas as pd
from matplotlib_venn import venn2, venn2_circles
import matplotlib.pyplot as plt

# Assuming subset_df is your DataFrame with 'cluster_labels_iPT' and 'cluster_labels_iTAL' columns

# Create sets of row indices for each cluster label in 'cluster_labels_iPT'
iPT_clusters = overlap_df['immune'].unique()
iPT_sets = {label: set(overlap_df.index[overlap_df['immune'] == label]) for label in iPT_clusters}

# Create sets of row indices for each cluster label in 'cluster_labels_iTAL'
iTAL_clusters = overlap_df['iTAL'].unique()
iTAL_sets = {label: set(overlap_df.index[overlap_df['iTAL'] == label]) for label in iTAL_clusters}

# Initialize the Venn diagram
plt.figure(figsize=(12, 12))

# Plot each combination of cluster labels
for i, iPT_label in enumerate(iPT_clusters):
    if iPT_label=='outlier':
      continue
    for j, iTAL_label in enumerate(iTAL_clusters):
        plt.subplot(len(iPT_clusters), len(iTAL_clusters), i * len(iTAL_clusters) + j + 1)
        venn2([iPT_sets[iPT_label], iTAL_sets[iTAL_label]], set_labels=(iPT_label, iTAL_label))
        venn2_circles([iPT_sets[iPT_label], iTAL_sets[iTAL_label]])


plt.tight_layout()
plt.savefig('overlap_immune_iTAL.png', dpi=450, bbox_inches='tight')
plt.show()

import pandas as pd
from matplotlib_venn import venn2, venn2_circles
import matplotlib.pyplot as plt

# Assuming subset_df is your DataFrame with 'cluster_labels_iPT' and 'cluster_labels_iTAL' columns

# Create sets of row indices for each cluster label in 'cluster_labels_iPT'
iPT_clusters = overlap_df['immune'].unique()
iPT_sets = {label: set(overlap_df.index[overlap_df['immune'] == label]) for label in iPT_clusters}

# Create sets of row indices for each cluster label in 'cluster_labels_iTAL'
iTAL_clusters = overlap_df['iPT'].unique()
iTAL_sets = {label: set(overlap_df.index[overlap_df['iPT'] == label]) for label in iTAL_clusters}

# Initialize the Venn diagram
plt.figure(figsize=(12, 12))

# Plot each combination of cluster labels
for i, iPT_label in enumerate(iPT_clusters):
    if iPT_label=='outlier':
      continue
    for j, iTAL_label in enumerate(iTAL_clusters):
        plt.subplot(len(iPT_clusters), len(iTAL_clusters), i * len(iTAL_clusters) + j + 1)
        venn2([iPT_sets[iPT_label], iTAL_sets[iTAL_label]], set_labels=(iPT_label, iTAL_label))
        venn2_circles([iPT_sets[iPT_label], iTAL_sets[iTAL_label]])


plt.tight_layout()
plt.savefig('overlap_immune_iPT.png', dpi=450, bbox_inches='tight')
plt.show()